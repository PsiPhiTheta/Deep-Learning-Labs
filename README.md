# Deep-Learning-Labs
Various ML implementations and mathematical proofs for the UofT Neural Networks and Deep Learning course

## Mathematical proofs

### HW1 - Neural Networks & Backpropagation

This folder contains the solutions to four problems relating to neural network design, computation graphs and backpropagation. Read the instructions [here](https://github.com/PsiPhiTheta/Deep-Learning-Labs/blob/master/math/hw1/Instructions.pdf) and the solutions [here](https://github.com/PsiPhiTheta/Deep-Learning-Labs/blob/master/math/hw1/Solutions.pdf).

### HW2 - Model-Agnostic Meta-Learning (MAML) and Optimisers (Momentum SGD, RMSProp, Adam)

This folder contains the implementation of Model-Agnostic Meta-Learning (MAML) using autodiff as well as mathematical proofs behind momentum SGD, RMSProp and Adam. Read the instructions [here](https://github.com/PsiPhiTheta/Deep-Learning-Labs/blob/master/math/hw2/Instructions.pdf) and the solutions [here](https://github.com/PsiPhiTheta/Deep-Learning-Labs/blob/master/math/hw2/Solutions.pdf). 

## Programming

### PA1 - Learning Distributed Word Representations (Neural Language Model)

This folder contains the implementation of a Neural Language Model and the analysis of its output characteristics. Read the instructions [here](https://github.com/PsiPhiTheta/Deep-Learning-Labs/blob/master/src/pa1/Instructions.pdf) and the solutions [here](https://github.com/PsiPhiTheta/Deep-Learning-Labs/blob/master/src/pa1/Solutions.pdf).
