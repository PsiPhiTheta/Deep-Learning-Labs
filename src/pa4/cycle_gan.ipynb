{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cycle_gan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TjPTaRB4mpCd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Colab FAQ\n",
        "\n",
        "For some basic overview and features offered in Colab notebooks, check out: [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "You need to use the colab GPU for this assignmentby selecting:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**"
      ]
    },
    {
      "metadata": {
        "id": "s9IS9B9-yUU5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup PyTorch\n",
        "All files are stored at /content/csc421/a4/ folder\n"
      ]
    },
    {
      "metadata": {
        "id": "Z-6MQhMOlHXD",
        "colab_type": "code",
        "outputId": "d72af8ab-32f6-45c8-f67e-c7a3cc209891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Setup python environment and change the current working directory\n",
        "######################################################################\n",
        "!pip install torch torchvision\n",
        "!pip install Pillow==4.0.0\n",
        "%mkdir -p /content/csc421/a4/\n",
        "%cd /content/csc421/a4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python2.7/dist-packages (1.0.1.post2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python2.7/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python2.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Collecting Pillow==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/99/0e3522a9764fe371bf9f7729404b1ef7d9c4fc49cbe5f1761c6e07812345/Pillow-4.0.0-cp27-cp27mu-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.6MB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mfastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.0.1.post2 which is incompatible.\u001b[0m\n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mtorchvision 0.2.2.post3 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 4.1.1\n",
            "    Uninstalling Pillow-4.1.1:\n",
            "      Successfully uninstalled Pillow-4.1.1\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/csc421/a4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9DaTdRNuUra7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Helper code"
      ]
    },
    {
      "metadata": {
        "id": "4BIpGwANoQOg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Utility functions"
      ]
    },
    {
      "metadata": {
        "id": "D-UJHBYZkh7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdb\n",
        "import argparse\n",
        "import pickle as pkl\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import tarfile\n",
        "import pickle\n",
        "import sys\n",
        "import scipy\n",
        "import scipy.misc\n",
        "\n",
        "def get_file(fname,\n",
        "             origin,\n",
        "             untar=False,\n",
        "             extract=False,\n",
        "             archive_format='auto',\n",
        "             cache_dir='data'):\n",
        "    datadir = os.path.join(cache_dir)\n",
        "    if not os.path.exists(datadir):\n",
        "        os.makedirs(datadir)\n",
        "\n",
        "    if untar:\n",
        "        untar_fpath = os.path.join(datadir, fname)\n",
        "        fpath = untar_fpath + '.tar.gz'\n",
        "    else:\n",
        "        fpath = os.path.join(datadir, fname)\n",
        "    \n",
        "    print(fpath)\n",
        "    if not os.path.exists(fpath):\n",
        "        print('Downloading data from', origin)\n",
        "\n",
        "        error_msg = 'URL fetch failure on {}: {} -- {}'\n",
        "        try:\n",
        "            try:\n",
        "                urlretrieve(origin, fpath)\n",
        "            except URLError as e:\n",
        "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
        "            except HTTPError as e:\n",
        "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
        "        except (Exception, KeyboardInterrupt) as e:\n",
        "            if os.path.exists(fpath):\n",
        "                os.remove(fpath)\n",
        "            raise\n",
        "\n",
        "    if untar:\n",
        "        if not os.path.exists(untar_fpath):\n",
        "            print('Extracting file.')\n",
        "            with tarfile.open(fpath) as archive:\n",
        "                archive.extractall(datadir)\n",
        "        return untar_fpath\n",
        "\n",
        "    if extract:\n",
        "        _extract_archive(fpath, datadir, archive_format)\n",
        "\n",
        "    return fpath\n",
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "        \n",
        "def to_var(tensor, cuda=True):\n",
        "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
        "\n",
        "        Arguments:\n",
        "            tensor: A Tensor object.\n",
        "            cuda: A boolean flag indicating whether to use the GPU.\n",
        "\n",
        "        Returns:\n",
        "            A Variable object, on the GPU if cuda==True.\n",
        "    \"\"\"\n",
        "    if cuda:\n",
        "        return Variable(tensor.cuda())\n",
        "    else:\n",
        "        return Variable(tensor)\n",
        "\n",
        "def to_data(x):\n",
        "    \"\"\"Converts variable to numpy.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cpu()\n",
        "    return x.data.numpy()\n",
        "\n",
        "def create_dir(directory):\n",
        "    \"\"\"Creates a directory if it doesn't already exist.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "def gan_checkpoint(iteration, G, D, opts):\n",
        "    \"\"\"Saves the parameters of the generator G and discriminator D.\n",
        "    \"\"\"\n",
        "    G_path = os.path.join(opts.checkpoint_dir, 'G.pkl')\n",
        "    D_path = os.path.join(opts.checkpoint_dir, 'D.pkl')\n",
        "    torch.save(G.state_dict(), G_path)\n",
        "    torch.save(D.state_dict(), D_path)\n",
        "\n",
        "def cyclegan_checkpoint(iteration, G_XtoY, G_YtoX, D_X, D_Y, opts):\n",
        "    \"\"\"Saves the parameters of both generators G_YtoX, G_XtoY and discriminators D_X, D_Y.\n",
        "    \"\"\"\n",
        "    G_XtoY_path = os.path.join(opts.checkpoint_dir, 'G_XtoY.pkl')\n",
        "    G_YtoX_path = os.path.join(opts.checkpoint_dir, 'G_YtoX.pkl')\n",
        "    D_X_path = os.path.join(opts.checkpoint_dir, 'D_X.pkl')\n",
        "    D_Y_path = os.path.join(opts.checkpoint_dir, 'D_Y.pkl')\n",
        "    torch.save(G_XtoY.state_dict(), G_XtoY_path)\n",
        "    torch.save(G_YtoX.state_dict(), G_YtoX_path)\n",
        "    torch.save(D_X.state_dict(), D_X_path)\n",
        "    torch.save(D_Y.state_dict(), D_Y_path)\n",
        "\n",
        "\n",
        "def load_checkpoint(opts):\n",
        "    \"\"\"Loads the generator and discriminator models from checkpoints.\n",
        "    \"\"\"\n",
        "    G_XtoY_path = os.path.join(opts.load, 'G_XtoY.pkl')\n",
        "    G_YtoX_path = os.path.join(opts.load, 'G_YtoX.pkl')\n",
        "    D_X_path = os.path.join(opts.load, 'D_X.pkl')\n",
        "    D_Y_path = os.path.join(opts.load, 'D_Y.pkl')\n",
        "\n",
        "    G_XtoY = CycleGenerator(conv_dim=opts.g_conv_dim, init_zero_weights=opts.init_zero_weights)\n",
        "    G_YtoX = CycleGenerator(conv_dim=opts.g_conv_dim, init_zero_weights=opts.init_zero_weights)\n",
        "    D_X = DCDiscriminator(conv_dim=opts.d_conv_dim)\n",
        "    D_Y = DCDiscriminator(conv_dim=opts.d_conv_dim)\n",
        "\n",
        "    G_XtoY.load_state_dict(torch.load(G_XtoY_path, map_location=lambda storage, loc: storage))\n",
        "    G_YtoX.load_state_dict(torch.load(G_YtoX_path, map_location=lambda storage, loc: storage))\n",
        "    D_X.load_state_dict(torch.load(D_X_path, map_location=lambda storage, loc: storage))\n",
        "    D_Y.load_state_dict(torch.load(D_Y_path, map_location=lambda storage, loc: storage))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        G_XtoY.cuda()\n",
        "        G_YtoX.cuda()\n",
        "        D_X.cuda()\n",
        "        D_Y.cuda()\n",
        "        print('Models moved to GPU.')\n",
        "\n",
        "    return G_XtoY, G_YtoX, D_X, D_Y\n",
        "\n",
        "\n",
        "def merge_images(sources, targets, opts):\n",
        "    \"\"\"Creates a grid consisting of pairs of columns, where the first column in\n",
        "    each pair contains images source images and the second column in each pair\n",
        "    contains images generated by the CycleGAN from the corresponding images in\n",
        "    the first column.\n",
        "    \"\"\"\n",
        "    _, _, h, w = sources.shape\n",
        "    row = int(np.sqrt(opts.batch_size))\n",
        "    merged = np.zeros([3, row*h, row*w*2])\n",
        "    for (idx, s, t) in (zip(range(row**2), sources, targets,)):\n",
        "        i = idx // row\n",
        "        j = idx % row\n",
        "        merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
        "        merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
        "    return merged.transpose(1, 2, 0)\n",
        "\n",
        "def create_image_grid(array, ncols=None):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    num_images, channels, cell_h, cell_w = array.shape\n",
        "    if not ncols:\n",
        "        ncols = int(np.sqrt(num_images))\n",
        "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
        "    result = np.zeros((cell_h*nrows, cell_w*ncols, channels), dtype=array.dtype)\n",
        "    for i in range(0, nrows):\n",
        "        for j in range(0, ncols):\n",
        "            result[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w, :] = array[i*ncols+j].transpose(1, 2, 0)\n",
        "\n",
        "    if channels == 1:\n",
        "        result = result.squeeze()\n",
        "    return result\n",
        "  \n",
        "def gan_save_samples(G, fixed_noise, iteration, opts):\n",
        "    generated_images = G(fixed_noise)\n",
        "    generated_images = to_data(generated_images)\n",
        "\n",
        "    grid = create_image_grid(generated_images)\n",
        "\n",
        "    # merged = merge_images(X, fake_Y, opts)\n",
        "    path = os.path.join(opts.sample_dir, 'sample-{:06d}.png'.format(iteration))\n",
        "    scipy.misc.imsave(path, grid)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "def cyclegan_save_samples(iteration, fixed_Y, fixed_X, G_YtoX, G_XtoY, opts):\n",
        "    \"\"\"Saves samples from both generators X->Y and Y->X.\n",
        "    \"\"\"\n",
        "    fake_X = G_YtoX(fixed_Y)\n",
        "    fake_Y = G_XtoY(fixed_X)\n",
        "\n",
        "    X, fake_X = to_data(fixed_X), to_data(fake_X)\n",
        "    Y, fake_Y = to_data(fixed_Y), to_data(fake_Y)\n",
        "\n",
        "    merged = merge_images(X, fake_Y, opts)\n",
        "    path = os.path.join(opts.sample_dir, 'sample-{:06d}-X-Y.png'.format(iteration))\n",
        "    scipy.misc.imsave(path, merged)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "    merged = merge_images(Y, fake_X, opts)\n",
        "    path = os.path.join(opts.sample_dir, 'sample-{:06d}-Y-X.png'.format(iteration))\n",
        "    scipy.misc.imsave(path, merged)\n",
        "    print('Saved {}'.format(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbvpn4MaV0I1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data loader"
      ]
    },
    {
      "metadata": {
        "id": "XVT4TNTOV3Eg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_emoji_loader(emoji_type, opts):\n",
        "    \"\"\"Creates training and test data loaders.\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "                    transforms.Scale(opts.image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                ])\n",
        "\n",
        "    train_path = os.path.join('data/emojis', emoji_type)\n",
        "    test_path = os.path.join('data/emojis', 'Test_{}'.format(emoji_type))\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(train_path, transform)\n",
        "    test_dataset = datasets.ImageFolder(test_path, transform)\n",
        "\n",
        "    train_dloader = DataLoader(dataset=train_dataset, batch_size=opts.batch_size, shuffle=True, num_workers=opts.num_workers)\n",
        "    test_dloader = DataLoader(dataset=test_dataset, batch_size=opts.batch_size, shuffle=False, num_workers=opts.num_workers)\n",
        "\n",
        "    return train_dloader, test_dloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRWfRdmVVjUl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation code"
      ]
    },
    {
      "metadata": {
        "id": "nSIhQp41q_Nu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_models(G_XtoY, G_YtoX, D_X, D_Y):\n",
        "    \"\"\"Prints model information for the generators and discriminators.\n",
        "    \"\"\"\n",
        "    if G_YtoX:\n",
        "      print(\"                 G_XtoY                \")\n",
        "      print(\"---------------------------------------\")\n",
        "      print(G_XtoY)\n",
        "      print(\"---------------------------------------\")\n",
        "\n",
        "      print(\"                 G_YtoX                \")\n",
        "      print(\"---------------------------------------\")\n",
        "      print(G_YtoX)\n",
        "      print(\"---------------------------------------\")\n",
        "\n",
        "      print(\"                  D_X                  \")\n",
        "      print(\"---------------------------------------\")\n",
        "      print(D_X)\n",
        "      print(\"---------------------------------------\")\n",
        "\n",
        "      print(\"                  D_Y                  \")\n",
        "      print(\"---------------------------------------\")\n",
        "      print(D_Y)\n",
        "      print(\"---------------------------------------\")\n",
        "    else:\n",
        "      print(\"                 G                     \")\n",
        "      print(\"---------------------------------------\")\n",
        "      print(G_XtoY)\n",
        "      print(\"---------------------------------------\")\n",
        "\n",
        "      print(\"                  D                    \")\n",
        "      print(\"---------------------------------------\")\n",
        "      print(D_X)\n",
        "      print(\"---------------------------------------\")\n",
        "\n",
        "      \n",
        "def create_model(opts):\n",
        "    \"\"\"Builds the generators and discriminators.\n",
        "    \"\"\"\n",
        "    if opts.Y is None:\n",
        "      ### GAN\n",
        "      G = DCGenerator(noise_size=opts.noise_size, conv_dim=opts.g_conv_dim)\n",
        "      D = DCDiscriminator(conv_dim=opts.d_conv_dim)\n",
        "\n",
        "      print_models(G, None, D, None)\n",
        "\n",
        "      if torch.cuda.is_available():\n",
        "          G.cuda()\n",
        "          D.cuda()\n",
        "          print('Models moved to GPU.')\n",
        "      return G, D\n",
        "          \n",
        "    else:\n",
        "      ### CycleGAN\n",
        "      G_XtoY = CycleGenerator(conv_dim=opts.g_conv_dim, init_zero_weights=opts.init_zero_weights)\n",
        "      G_YtoX = CycleGenerator(conv_dim=opts.g_conv_dim, init_zero_weights=opts.init_zero_weights)\n",
        "      D_X = DCDiscriminator(conv_dim=opts.d_conv_dim)\n",
        "      D_Y = DCDiscriminator(conv_dim=opts.d_conv_dim)\n",
        "\n",
        "      print_models(G_XtoY, G_YtoX, D_X, D_Y)\n",
        "\n",
        "      if torch.cuda.is_available():\n",
        "          G_XtoY.cuda()\n",
        "          G_YtoX.cuda()\n",
        "          D_X.cuda()\n",
        "          D_Y.cuda()\n",
        "          print('Models moved to GPU.')\n",
        "      return G_XtoY, G_YtoX, D_X, D_Y\n",
        "\n",
        "\n",
        "def train(opts):\n",
        "    \"\"\"Loads the data, creates checkpoint and sample directories, and starts the training loop.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create train and test dataloaders for images from the two domains X and Y\n",
        "    dataloader_X, test_dataloader_X = get_emoji_loader(emoji_type=opts.X, opts=opts)\n",
        "    if opts.Y:\n",
        "      dataloader_Y, test_dataloader_Y = get_emoji_loader(emoji_type=opts.Y, opts=opts)\n",
        "\n",
        "    # Create checkpoint and sample directories\n",
        "    create_dir(opts.checkpoint_dir)\n",
        "    create_dir(opts.sample_dir)\n",
        "\n",
        "    # Start training\n",
        "    if opts.Y is None:\n",
        "      G, D = gan_training_loop(dataloader_X, test_dataloader_X, opts)\n",
        "      return G, D\n",
        "    else:\n",
        "      G_XtoY, G_YtoX, D_X, D_Y = cyclegan_training_loop(dataloader_X, dataloader_Y, test_dataloader_X, test_dataloader_Y, opts)\n",
        "      return G_XtoY, G_YtoX, D_X, D_Y\n",
        "\n",
        "\n",
        "def print_opts(opts):\n",
        "    \"\"\"Prints the values of all command-line arguments.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Opts'.center(80))\n",
        "    print('-' * 80)\n",
        "    for key in opts.__dict__:\n",
        "        if opts.__dict__[key]:\n",
        "            print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
        "    print('=' * 80)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXNsLNkOn38w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Your code for generators and discriminators"
      ]
    },
    {
      "metadata": {
        "id": "u0KxX0sDpXKb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper modules"
      ]
    },
    {
      "metadata": {
        "id": "y7s0etAmpUgT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_noise(batch_size, dim):\n",
        "    \"\"\"\n",
        "    Generate a PyTorch Tensor of uniform random noise.\n",
        "\n",
        "    Input:\n",
        "    - batch_size: Integer giving the batch size of noise to generate.\n",
        "    - dim: Integer giving the dimension of noise to generate.\n",
        "\n",
        "    Output:\n",
        "    - A PyTorch Tensor of shape (batch_size, dim, 1, 1) containing uniform\n",
        "      random noise in the range (-1, 1).\n",
        "    \"\"\"\n",
        "    return to_var(torch.rand(batch_size, dim) * 2 - 1).unsqueeze(2).unsqueeze(3)\n",
        "  \n",
        "\n",
        "def upconv(in_channels, out_channels, kernel_size, stride=2, padding=2, batch_norm=True):\n",
        "    \"\"\"Creates a upsample-and-convolution layer, with optional batch normalization.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    if stride>1:\n",
        "      layers.append(nn.Upsample(scale_factor=stride))\n",
        "    conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
        "    layers.append(conv_layer)\n",
        "    if batch_norm:\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def conv(in_channels, out_channels, kernel_size, stride=2, padding=2, batch_norm=True, init_zero_weights=False):\n",
        "    \"\"\"Creates a convolutional layer, with optional batch normalization.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
        "    if init_zero_weights:\n",
        "        conv_layer.weight.data = torch.randn(out_channels, in_channels, kernel_size, kernel_size) * 0.001\n",
        "    layers.append(conv_layer)\n",
        "\n",
        "    if batch_norm:\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "    return nn.Sequential(*layers)\n",
        "  \n",
        "  \n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, conv_dim):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_layer = conv(in_channels=conv_dim, out_channels=conv_dim, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.conv_layer(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S0_YbBwe5k35",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "_BAfi_8yWB3y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GAN generator"
      ]
    },
    {
      "metadata": {
        "id": "9ztmyA5Ro67o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DCGenerator(nn.Module):\n",
        "    def __init__(self, noise_size, conv_dim):\n",
        "        super(DCGenerator, self).__init__()\n",
        "\n",
        "        self.conv_dim = conv_dim\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: CREATE ARCHITECTURE   ##\n",
        "        \n",
        "        self.linear_bn = upconv(noise_size, conv_dim*4, 4, padding=3, stride=1) # upconv(in_channels, out_channels, kernel_size, stride=2, padding=2, batch_norm=True)\n",
        "        self.upconv1 = upconv(conv_dim*4, conv_dim*2, 5)\n",
        "        self.upconv2 = upconv(conv_dim*2, conv_dim, 5)\n",
        "        self.upconv3 = upconv(conv_dim, 3, 5, batch_norm=False)\n",
        "        \n",
        "        ###########################################\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"Generates an image given a sample of random noise.\n",
        "\n",
        "            Input\n",
        "            -----\n",
        "                z: BS x noise_size x 1 x 1   -->  BSx100x1x1 (during training)\n",
        "\n",
        "            Output\n",
        "            ------\n",
        "                out: BS x channels x image_width x image_height  -->  BSx3x32x32 (during training)\n",
        "        \"\"\"\n",
        "        batch_size = z.size(0)\n",
        "        \n",
        "        out = F.relu(self.linear_bn(z)).view(-1, self.conv_dim*4, 4, 4)    # BS x 128 x 4 x 4\n",
        "        out = F.relu(self.upconv1(out))  # BS x 64 x 8 x 8\n",
        "        out = F.relu(self.upconv2(out))  # BS x 32 x 16 x 16\n",
        "        out = F.tanh(self.upconv3(out))  # BS x 3 x 32 x 32\n",
        "        \n",
        "        out_size = out.size()\n",
        "        if out_size != torch.Size([batch_size, 3, 32, 32]):\n",
        "          raise ValueError(\"expect {} x 3 x 32 x 32, but get {}\".format(batch_size, out_size))\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cG4uqAVPp8_B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GAN discriminator"
      ]
    },
    {
      "metadata": {
        "id": "0GkjXydnqARR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DCDiscriminator(nn.Module):\n",
        "    \"\"\"Defines the architecture of the discriminator network.\n",
        "       Note: Both discriminators D_X and D_Y have the same architecture in this assignment.\n",
        "    \"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(DCDiscriminator, self).__init__()\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: CREATE ARCHITECTURE   ##\n",
        "        \n",
        "        self.conv1 = conv(3, conv_dim/2, 5) # conv(in_channels, out_channels, kernel_size, stride=2, padding=2, batch_norm=True, init_zero_weights=False)\n",
        "        self.conv2 = conv(conv_dim/2, conv_dim, 5)\n",
        "        self.conv3 = conv(conv_dim, conv_dim*2, 5)\n",
        "        self.conv4 = conv(conv_dim*2, 1, 4, stride=1, padding=0, batch_norm=False)\n",
        "        \n",
        "        ###########################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        out = F.relu(self.conv1(x))    # BS x 64 x 16 x 16\n",
        "        out = F.relu(self.conv2(out))    # BS x 64 x 8 x 8\n",
        "        out = F.relu(self.conv3(out))    # BS x 64 x 4 x 4\n",
        "\n",
        "        out = self.conv4(out).squeeze()\n",
        "        out_size = out.size()\n",
        "        if out_size != torch.Size([batch_size,]):\n",
        "          raise ValueError(\"expect {} x 1, but get {}\".format(batch_size, out_size))\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G8RtBMu55ysm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###GAN training loop"
      ]
    },
    {
      "metadata": {
        "id": "MxIJ2Zua51KI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gan_training_loop(dataloader, test_dataloader, opts):\n",
        "    \"\"\"Runs the training loop.\n",
        "        * Saves checkpoint every opts.checkpoint_every iterations\n",
        "        * Saves generated samples every opts.sample_every iterations\n",
        "    \"\"\"\n",
        "\n",
        "    # Create generators and discriminators\n",
        "    G, D = create_model(opts)\n",
        "\n",
        "    g_params = G.parameters()  # Get generator parameters\n",
        "    d_params = D.parameters()  # Get discriminator parameters\n",
        "\n",
        "    # Create optimizers for the generators and discriminators\n",
        "    g_optimizer = optim.Adam(g_params, opts.lr, [opts.beta1, opts.beta2])\n",
        "    d_optimizer = optim.Adam(d_params, opts.lr*2., [opts.beta1, opts.beta2])\n",
        "\n",
        "    train_iter = iter(dataloader)\n",
        "\n",
        "    test_iter = iter(test_dataloader)\n",
        "\n",
        "    # Get some fixed data from domains X and Y for sampling. These are images that are held\n",
        "    # constant throughout training, that allow us to inspect the model's performance.\n",
        "    fixed_noise = sample_noise(100, opts.noise_size)  # # 100 x noise_size x 1 x 1\n",
        "\n",
        "    iter_per_epoch = len(train_iter)\n",
        "    total_train_iters = opts.train_iters\n",
        "\n",
        "    try:\n",
        "      for iteration in range(1, opts.train_iters+1):\n",
        "\n",
        "          # Reset data_iter for each epoch\n",
        "          if iteration % iter_per_epoch == 0:\n",
        "              train_iter = iter(dataloader)\n",
        "\n",
        "          real_images, real_labels = train_iter.next()\n",
        "          real_images, real_labels = to_var(real_images), to_var(real_labels).long().squeeze()\n",
        "\n",
        "          ###########################################\n",
        "          ###        TRAIN THE DISCRIMINATOR      ###\n",
        "          \n",
        "          d_optimizer.zero_grad()\n",
        "          \n",
        "          # FILL THIS IN\n",
        "          # 1. Compute the discriminator loss on real images\n",
        "          D_real_loss = sum((D(real_images)-1)**2) / (2*opts.batch_size)  \n",
        "\n",
        "          # 2. Sample noise\n",
        "          noise = sample_noise(opts.batch_size, opts.noise_size) \n",
        "\n",
        "          # 3. Generate fake images from the noise\n",
        "          fake_images = G(noise)\n",
        "\n",
        "          # 4. Compute the discriminator loss on the fake images\n",
        "          D_fake_loss = sum(D(fake_images)**2) / (2*opts.batch_size)        \n",
        "\n",
        "          # 5. Compute the total discriminator loss\n",
        "          D_total_loss = D_real_loss + D_fake_loss\n",
        "          \n",
        "          ###########################################\n",
        "          \n",
        "          D_total_loss.backward()\n",
        "          d_optimizer.step()\n",
        "        \n",
        "          ###########################################\n",
        "          ###          TRAIN THE GENERATOR        ###\n",
        "          \n",
        "          g_optimizer.zero_grad()\n",
        "\n",
        "          # FILL THIS IN\n",
        "          # 1. Sample noise\n",
        "          noise = sample_noise(opts.batch_size, opts.noise_size)  \n",
        "\n",
        "          # 2. Generate fake images from the noise\n",
        "          fake_images = G(noise)\n",
        "\n",
        "          # 3. Compute the generator loss\n",
        "          G_loss = sum((D(fake_images)-1)**2) / opts.batch_size\n",
        "          \n",
        "          ###########################################\n",
        "          \n",
        "          G_loss.backward()\n",
        "          g_optimizer.step()\n",
        "\n",
        "\n",
        "          # Print the log info\n",
        "          if iteration % opts.log_step == 0:\n",
        "              print('Iteration [{:4d}/{:4d}] | D_real_loss: {:6.4f} | D_fake_loss: {:6.4f} | G_loss: {:6.4f}'.format(\n",
        "                     iteration, total_train_iters, D_real_loss.item(), D_fake_loss.item(), G_loss.item()))\n",
        "\n",
        "          # Save the generated samples\n",
        "          if iteration % opts.sample_every == 0:\n",
        "              gan_save_samples(G, fixed_noise, iteration, opts)\n",
        "\n",
        "          # Save the model parameters\n",
        "          if iteration % opts.checkpoint_every == 0:\n",
        "              gan_checkpoint(iteration, G, D, opts)\n",
        "              \n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting early from training.')\n",
        "        return G, D\n",
        "      \n",
        "    return G, D\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ptSA0rHUuNHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##CycleGAN"
      ]
    },
    {
      "metadata": {
        "id": "I8lIyRNGuOrv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###CycleGAN generator"
      ]
    },
    {
      "metadata": {
        "id": "VVswO-M-uXLo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CycleGenerator(nn.Module):\n",
        "    \"\"\"Defines the architecture of the generator network.\n",
        "       Note: Both generators G_XtoY and G_YtoX have the same architecture in this assignment.\n",
        "    \"\"\"\n",
        "    def __init__(self, conv_dim=64, init_zero_weights=False):\n",
        "        super(CycleGenerator, self).__init__()\n",
        "\n",
        "        ###########################################\n",
        "        ##   FILL THIS IN: CREATE ARCHITECTURE   ##\n",
        "        \n",
        "        # 1. Define the encoder part of the generator (that extracts features from the input image)\n",
        "        self.conv1 = conv(3, conv_dim, 5) # conv(in_channels, out_channels, kernel_size, stride=2, padding=2, batch_norm=True, init_zero_weights=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 5)\n",
        "\n",
        "        # 2. Define the transformation part of the generator\n",
        "        self.resnet_block = ResnetBlock(conv_dim*2)\n",
        "\n",
        "        # 3. Define the decoder part of the generator (that builds up the output image from features)\n",
        "        self.upconv1 = upconv(conv_dim*2, conv_dim, 5) # upconv(in_channels, out_channels, kernel_size, stride=2, padding=2, batch_norm=True)\n",
        "        self.upconv2 = upconv(conv_dim, 3, 5, batch_norm=False)\n",
        "        \n",
        "        ###########################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Generates an image conditioned on an input image.\n",
        "\n",
        "            Input\n",
        "            -----\n",
        "                x: BS x 3 x 32 x 32\n",
        "\n",
        "            Output\n",
        "            ------\n",
        "                out: BS x 3 x 32 x 32\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        out = F.relu(self.conv1(x))            # BS x 32 x 16 x 16\n",
        "        out = F.relu(self.conv2(out))          # BS x 64 x 8 x 8\n",
        "        \n",
        "        out = F.relu(self.resnet_block(out))   # BS x 64 x 8 x 8\n",
        "\n",
        "        out = F.relu(self.upconv1(out))        # BS x 32 x 16 x 16\n",
        "        out = F.tanh(self.upconv2(out))        # BS x 3 x 32 x 32\n",
        "        \n",
        "        out_size = out.size()\n",
        "        if out_size != torch.Size([batch_size, 3, 32, 32]):\n",
        "          raise ValueError(\"expect {} x 3 x 32 x 32, but get {}\".format(batch_size, out_size))\n",
        "\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYVbPQ6OuB1w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###CycleGAN training loop"
      ]
    },
    {
      "metadata": {
        "id": "CFfQjxstuGaA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cyclegan_training_loop(dataloader_X, dataloader_Y, test_dataloader_X, test_dataloader_Y, opts):\n",
        "    \"\"\"Runs the training loop.\n",
        "        * Saves checkpoint every opts.checkpoint_every iterations\n",
        "        * Saves generated samples every opts.sample_every iterations\n",
        "    \"\"\"\n",
        "\n",
        "    # Create generators and discriminators\n",
        "    G_XtoY, G_YtoX, D_X, D_Y = create_model(opts)\n",
        "\n",
        "    g_params = list(G_XtoY.parameters()) + list(G_YtoX.parameters())  # Get generator parameters\n",
        "    d_params = list(D_X.parameters()) + list(D_Y.parameters())  # Get discriminator parameters\n",
        "\n",
        "    # Create optimizers for the generators and discriminators\n",
        "    g_optimizer = optim.Adam(g_params, opts.lr, [opts.beta1, opts.beta2])\n",
        "    d_optimizer = optim.Adam(d_params, opts.lr, [opts.beta1, opts.beta2])\n",
        "\n",
        "    iter_X = iter(dataloader_X)\n",
        "    iter_Y = iter(dataloader_Y)\n",
        "\n",
        "    test_iter_X = iter(test_dataloader_X)\n",
        "    test_iter_Y = iter(test_dataloader_Y)\n",
        "\n",
        "    # Get some fixed data from domains X and Y for sampling. These are images that are held\n",
        "    # constant throughout training, that allow us to inspect the model's performance.\n",
        "    fixed_X = to_var(test_iter_X.next()[0])\n",
        "    fixed_Y = to_var(test_iter_Y.next()[0])\n",
        "\n",
        "    iter_per_epoch = min(len(iter_X), len(iter_Y))\n",
        "\n",
        "    try:\n",
        "      for iteration in range(1, opts.train_iters+1):\n",
        "\n",
        "          # Reset data_iter for each epoch\n",
        "          if iteration % iter_per_epoch == 0:\n",
        "              iter_X = iter(dataloader_X)\n",
        "              iter_Y = iter(dataloader_Y)\n",
        "\n",
        "          images_X, labels_X = iter_X.next()\n",
        "          images_X, labels_X = to_var(images_X), to_var(labels_X).long().squeeze()\n",
        "\n",
        "          images_Y, labels_Y = iter_Y.next()\n",
        "          images_Y, labels_Y = to_var(images_Y), to_var(labels_Y).long().squeeze()\n",
        "\n",
        "\n",
        "          # ============================================\n",
        "          #            TRAIN THE DISCRIMINATORS\n",
        "          # ============================================\n",
        "\n",
        "          #########################################\n",
        "          ##             FILL THIS IN            ##\n",
        "          \n",
        "          # Train with real images\n",
        "          d_optimizer.zero_grad()\n",
        "\n",
        "          # 1. Compute the discriminator losses on real images\n",
        "          D_X_loss = torch.sum(torch.pow(D_X(images_X)-1,2)) / (2*opts.batch_size) # torch.mean(((D_X(images_X)-1)**2)) not good, try F.mse_loss(D_X_preds, Variable(torch.ones(labels_X.size(0))))or nn.MSELoss(size_average=True, reduce=True)(<fake>, <target>)\n",
        "          D_Y_loss =torch.sum(torch.pow(D_Y(images_Y)-1,2)) / (2*opts.batch_size)\n",
        "          \n",
        "          d_real_loss = D_X_loss + D_Y_loss\n",
        "          d_real_loss.backward()\n",
        "          d_optimizer.step()\n",
        "\n",
        "          # Train with fake images\n",
        "          d_optimizer.zero_grad()\n",
        "\n",
        "          # 2. Generate fake images that look like domain X based on real images in domain Y\n",
        "          fake_X = G_YtoX(images_Y)\n",
        "\n",
        "          # 3. Compute the loss for D_X\n",
        "          D_X_loss = torch.sum(torch.pow(D_X(fake_X),2)) / (2*opts.batch_size)\n",
        "\n",
        "          # 4. Generate fake images that look like domain Y based on real images in domain X\n",
        "          fake_Y = G_XtoY(images_X)\n",
        "\n",
        "          # 5. Compute the loss for D_Y\n",
        "          D_Y_loss = torch.sum(torch.pow(D_Y(fake_Y),2)) / (2*opts.batch_size)\n",
        "          \n",
        "          #########################################\n",
        "\n",
        "          d_fake_loss = D_X_loss + D_Y_loss\n",
        "          d_fake_loss.backward()\n",
        "          d_optimizer.step()\n",
        "\n",
        "          \n",
        "          \n",
        "          # =========================================\n",
        "          #            TRAIN THE GENERATORS\n",
        "          # =========================================\n",
        "\n",
        "\n",
        "          #########################################\n",
        "          ##    FILL THIS IN: Y--X-->Y CYCLE     ##\n",
        "          \n",
        "          g_optimizer.zero_grad()\n",
        "\n",
        "          # 1. Generate fake images that look like domain X based on real images in domain Y\n",
        "          fake_X = G_YtoX(images_Y)\n",
        "\n",
        "          # 2. Compute the generator loss based on domain X\n",
        "          g_loss = torch.sum(torch.pow(D_X(fake_X)-1,2)) / (opts.batch_size)\n",
        "                    \n",
        "          # 3. Compute the cycle consistency loss (the reconstruction loss)\n",
        "          reconstructed_Y = G_XtoY(fake_X)\n",
        "          cycle_consistency_loss = (images_Y-reconstructed_Y).abs().sum() / (images_Y).size(0) # or opts.batch_size\n",
        "          \n",
        "          #########################################\n",
        "          \n",
        "          g_loss += opts.lambda_cycle * cycle_consistency_loss\n",
        "          \n",
        "          g_loss.backward()\n",
        "          g_optimizer.step()\n",
        "          \n",
        "          \n",
        "\n",
        "          #########################################\n",
        "          ##    FILL THIS IN: X--Y-->X CYCLE     ##\n",
        "          \n",
        "          g_optimizer.zero_grad()\n",
        "\n",
        "          # 1. Generate fake images that look like domain Y based on real images in domain X\n",
        "          fake_Y = G_XtoY(images_X)\n",
        "\n",
        "          # 2. Compute the generator loss based on domain Y\n",
        "          g_loss = torch.sum(torch.pow(D_Y(fake_Y)-1,2)) / (opts.batch_size)\n",
        "\n",
        "          # 3. Compute the cycle consistency loss (the reconstruction loss)\n",
        "          reconstructed_X = G_YtoX(fake_Y)\n",
        "          cycle_consistency_loss = (images_X-reconstructed_X).abs().sum() / (images_X).size(0)\n",
        "          \n",
        "          #########################################\n",
        "          \n",
        "          g_loss += opts.lambda_cycle * cycle_consistency_loss\n",
        "\n",
        "          g_loss.backward()\n",
        "          g_optimizer.step()\n",
        "\n",
        "\n",
        "          # Print the log info\n",
        "          if iteration % opts.log_step == 0:\n",
        "              print('Iteration [{:5d}/{:5d}] | d_real_loss: {:6.4f} | d_Y_loss: {:6.4f} | d_X_loss: {:6.4f} | '\n",
        "                    'd_fake_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
        "                      iteration, opts.train_iters, d_real_loss.item(), D_Y_loss.item(),\n",
        "                      D_X_loss.item(), d_fake_loss.item(), g_loss.item()))\n",
        "\n",
        "\n",
        "          # Save the generated samples\n",
        "          if iteration % opts.sample_every == 0:\n",
        "              cyclegan_save_samples(iteration, fixed_Y, fixed_X, G_YtoX, G_XtoY, opts)\n",
        "\n",
        "\n",
        "          # Save the model parameters\n",
        "          if iteration % opts.checkpoint_every == 0:\n",
        "              cyclegan_checkpoint(iteration, G_XtoY, G_YtoX, D_X, D_Y, opts)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting early from training.')\n",
        "        return G_XtoY, G_YtoX, D_X, D_Y\n",
        "      \n",
        "    return G_XtoY, G_YtoX, D_X, D_Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XuNFd6LNo0-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ]
    },
    {
      "metadata": {
        "id": "kiUwiOITHTW4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ]
    },
    {
      "metadata": {
        "id": "xwcFjsEpHRbI",
        "colab_type": "code",
        "outputId": "61038ca4-1f3f-4855-b5bc-45ae3bb573ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Download Translation datasets\n",
        "######################################################################\n",
        "data_fpath = get_file(fname='emojis', \n",
        "                         origin='http://www.cs.toronto.edu/~jba/emojis.tar.gz', \n",
        "                         untar=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/emojis.tar.gz\n",
            "('Downloading data from', 'http://www.cs.toronto.edu/~jba/emojis.tar.gz')\n",
            "Extracting file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hmQmyJDSRFKR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "0LKaRF1jwhH7",
        "colab_type": "code",
        "outputId": "b5fa0616-0a6b-4298-80e2-9c0b39bc9722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1989
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 11\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'image_size':32, \n",
        "              'g_conv_dim':32, \n",
        "              'd_conv_dim':64,\n",
        "              'noise_size':100,\n",
        "              'num_workers': 0,\n",
        "              'train_iters':5000,\n",
        "              'X':'Windows',  # options: 'Windows' / 'Apple'\n",
        "              'Y': None,\n",
        "              'lr':0.0003,\n",
        "              'beta1':0.5,\n",
        "              'beta2':0.999,\n",
        "              'batch_size':32, \n",
        "              'checkpoint_dir': 'checkpoints_gan',\n",
        "              'sample_dir': 'samples_gan',\n",
        "              'load': None,\n",
        "              'log_step':200,\n",
        "              'sample_every':200,\n",
        "              'checkpoint_every':1000,\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "print_opts(args)\n",
        "G, D = train(args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                           sample_every: 200                                    \n",
            "                       checkpoint_every: 1000                                   \n",
            "                             batch_size: 32                                     \n",
            "                             image_size: 32                                     \n",
            "                         checkpoint_dir: checkpoints_gan                        \n",
            "                                      X: Windows                                \n",
            "                             d_conv_dim: 64                                     \n",
            "                             noise_size: 100                                    \n",
            "                            train_iters: 5000                                   \n",
            "                             sample_dir: samples_gan                            \n",
            "                               log_step: 200                                    \n",
            "                                     lr: 0.0003                                 \n",
            "                                  beta2: 0.999                                  \n",
            "                                  beta1: 0.5                                    \n",
            "                             g_conv_dim: 32                                     \n",
            "================================================================================\n",
            "                 G                     \n",
            "---------------------------------------\n",
            "DCGenerator(\n",
            "  (linear_bn): Sequential(\n",
            "    (0): Conv2d(100, 128, kernel_size=(4, 4), stride=(1, 1), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv3): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D                    \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "Models moved to GPU.\n",
            "Iteration [ 200/5000] | D_real_loss: 0.0822 | D_fake_loss: 0.0178 | G_loss: 0.5765\n",
            "Saved samples_gan/sample-000200.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:196: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [ 400/5000] | D_real_loss: 0.0193 | D_fake_loss: 0.1025 | G_loss: 1.2373\n",
            "Saved samples_gan/sample-000400.png\n",
            "Iteration [ 600/5000] | D_real_loss: 0.0382 | D_fake_loss: 0.0103 | G_loss: 0.7749\n",
            "Saved samples_gan/sample-000600.png\n",
            "Iteration [ 800/5000] | D_real_loss: 0.0056 | D_fake_loss: 0.0207 | G_loss: 1.2606\n",
            "Saved samples_gan/sample-000800.png\n",
            "Iteration [1000/5000] | D_real_loss: 0.0060 | D_fake_loss: 0.0179 | G_loss: 1.0447\n",
            "Saved samples_gan/sample-001000.png\n",
            "Iteration [1200/5000] | D_real_loss: 0.0067 | D_fake_loss: 0.0109 | G_loss: 1.0431\n",
            "Saved samples_gan/sample-001200.png\n",
            "Iteration [1400/5000] | D_real_loss: 0.0224 | D_fake_loss: 0.0436 | G_loss: 1.1851\n",
            "Saved samples_gan/sample-001400.png\n",
            "Iteration [1600/5000] | D_real_loss: 0.0248 | D_fake_loss: 0.0102 | G_loss: 0.7712\n",
            "Saved samples_gan/sample-001600.png\n",
            "Iteration [1800/5000] | D_real_loss: 0.0065 | D_fake_loss: 0.0073 | G_loss: 0.8390\n",
            "Saved samples_gan/sample-001800.png\n",
            "Iteration [2000/5000] | D_real_loss: 0.0045 | D_fake_loss: 0.0097 | G_loss: 1.0051\n",
            "Saved samples_gan/sample-002000.png\n",
            "Iteration [2200/5000] | D_real_loss: 0.0064 | D_fake_loss: 0.0046 | G_loss: 1.0538\n",
            "Saved samples_gan/sample-002200.png\n",
            "Iteration [2400/5000] | D_real_loss: 0.0130 | D_fake_loss: 0.0075 | G_loss: 0.7574\n",
            "Saved samples_gan/sample-002400.png\n",
            "Iteration [2600/5000] | D_real_loss: 0.0076 | D_fake_loss: 0.0132 | G_loss: 1.2985\n",
            "Saved samples_gan/sample-002600.png\n",
            "Iteration [2800/5000] | D_real_loss: 0.0169 | D_fake_loss: 0.0134 | G_loss: 0.8565\n",
            "Saved samples_gan/sample-002800.png\n",
            "Iteration [3000/5000] | D_real_loss: 0.0141 | D_fake_loss: 0.0237 | G_loss: 1.0065\n",
            "Saved samples_gan/sample-003000.png\n",
            "Iteration [3200/5000] | D_real_loss: 0.0105 | D_fake_loss: 0.0107 | G_loss: 1.1378\n",
            "Saved samples_gan/sample-003200.png\n",
            "Iteration [3400/5000] | D_real_loss: 0.0043 | D_fake_loss: 0.0040 | G_loss: 1.0060\n",
            "Saved samples_gan/sample-003400.png\n",
            "Iteration [3600/5000] | D_real_loss: 0.0072 | D_fake_loss: 0.0119 | G_loss: 1.2579\n",
            "Saved samples_gan/sample-003600.png\n",
            "Iteration [3800/5000] | D_real_loss: 0.0044 | D_fake_loss: 0.0048 | G_loss: 0.9733\n",
            "Saved samples_gan/sample-003800.png\n",
            "Iteration [4000/5000] | D_real_loss: 0.0208 | D_fake_loss: 0.0083 | G_loss: 1.2132\n",
            "Saved samples_gan/sample-004000.png\n",
            "Iteration [4200/5000] | D_real_loss: 0.0496 | D_fake_loss: 0.0227 | G_loss: 0.7664\n",
            "Saved samples_gan/sample-004200.png\n",
            "Iteration [4400/5000] | D_real_loss: 0.0085 | D_fake_loss: 0.0056 | G_loss: 0.9743\n",
            "Saved samples_gan/sample-004400.png\n",
            "Iteration [4600/5000] | D_real_loss: 0.0043 | D_fake_loss: 0.0044 | G_loss: 0.6984\n",
            "Saved samples_gan/sample-004600.png\n",
            "Iteration [4800/5000] | D_real_loss: 0.0075 | D_fake_loss: 0.0052 | G_loss: 0.8118\n",
            "Saved samples_gan/sample-004800.png\n",
            "Iteration [5000/5000] | D_real_loss: 0.0115 | D_fake_loss: 0.0186 | G_loss: 1.0899\n",
            "Saved samples_gan/sample-005000.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7cP7nl5NRJbu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CycleGAN"
      ]
    },
    {
      "metadata": {
        "id": "nKlyfbuPDXDR",
        "colab_type": "code",
        "outputId": "fef5309f-6459-4093-d774-6ce0ab532f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 4\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'image_size':32, \n",
        "              'g_conv_dim':32, \n",
        "              'd_conv_dim':32,\n",
        "              'init_zero_weights': False,\n",
        "              'num_workers': 0,\n",
        "              'train_iters':5000,\n",
        "              'X':'Apple',\n",
        "              'Y':'Windows',\n",
        "              'lambda_cycle': 0.015,\n",
        "              'lr':0.0003,\n",
        "              'beta1':0.3,\n",
        "              'beta2':0.999,\n",
        "              'batch_size':32, \n",
        "              'checkpoint_dir': 'checkpoints_cyclegan',\n",
        "              'sample_dir': 'samples_cyclegan',\n",
        "              'load': None,\n",
        "              'log_step':200,\n",
        "              'sample_every':200,\n",
        "              'checkpoint_every':1000,\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "\n",
        "print_opts(args)\n",
        "G_XtoY, G_YtoX, D_X, D_Y = train(args)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                           sample_every: 200                                    \n",
            "                           lambda_cycle: 0.015                                  \n",
            "                       checkpoint_every: 1000                                   \n",
            "                             batch_size: 32                                     \n",
            "                                      Y: Windows                                \n",
            "                             image_size: 32                                     \n",
            "                         checkpoint_dir: checkpoints_cyclegan                   \n",
            "                                      X: Apple                                  \n",
            "                             d_conv_dim: 32                                     \n",
            "                            train_iters: 5000                                   \n",
            "                             sample_dir: samples_cyclegan                       \n",
            "                               log_step: 200                                    \n",
            "                                     lr: 0.0003                                 \n",
            "                                  beta2: 0.999                                  \n",
            "                                  beta1: 0.3                                    \n",
            "                             g_conv_dim: 32                                     \n",
            "================================================================================\n",
            "                 G_XtoY                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                 G_YtoX                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_X                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_Y                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/torchvision/transforms/transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Models moved to GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  \"color for transparency\")\n",
            "/usr/local/lib/python2.7/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [  200/ 5000] | d_real_loss: 0.1062 | d_Y_loss: 0.0201 | d_X_loss: 0.0809 | d_fake_loss: 0.1010 | g_loss: 7.6709\n",
            "Saved samples_cyclegan/sample-000200-X-Y.png\n",
            "Saved samples_cyclegan/sample-000200-Y-X.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:210: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:215: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [  400/ 5000] | d_real_loss: 0.1217 | d_Y_loss: 0.0296 | d_X_loss: 0.0544 | d_fake_loss: 0.0840 | g_loss: 7.5013\n",
            "Saved samples_cyclegan/sample-000400-X-Y.png\n",
            "Saved samples_cyclegan/sample-000400-Y-X.png\n",
            "Iteration [  600/ 5000] | d_real_loss: 0.1202 | d_Y_loss: 0.0197 | d_X_loss: 0.0558 | d_fake_loss: 0.0755 | g_loss: 7.3788\n",
            "Saved samples_cyclegan/sample-000600-X-Y.png\n",
            "Saved samples_cyclegan/sample-000600-Y-X.png\n",
            "Iteration [  800/ 5000] | d_real_loss: 0.0622 | d_Y_loss: 0.0251 | d_X_loss: 0.0292 | d_fake_loss: 0.0543 | g_loss: 6.7150\n",
            "Saved samples_cyclegan/sample-000800-X-Y.png\n",
            "Saved samples_cyclegan/sample-000800-Y-X.png\n",
            "Iteration [ 1000/ 5000] | d_real_loss: 0.0381 | d_Y_loss: 0.0159 | d_X_loss: 0.0448 | d_fake_loss: 0.0607 | g_loss: 7.4413\n",
            "Saved samples_cyclegan/sample-001000-X-Y.png\n",
            "Saved samples_cyclegan/sample-001000-Y-X.png\n",
            "Iteration [ 1200/ 5000] | d_real_loss: 0.0592 | d_Y_loss: 0.0166 | d_X_loss: 0.0252 | d_fake_loss: 0.0418 | g_loss: 6.5573\n",
            "Saved samples_cyclegan/sample-001200-X-Y.png\n",
            "Saved samples_cyclegan/sample-001200-Y-X.png\n",
            "Iteration [ 1400/ 5000] | d_real_loss: 0.0411 | d_Y_loss: 0.0122 | d_X_loss: 0.0229 | d_fake_loss: 0.0351 | g_loss: 6.4649\n",
            "Saved samples_cyclegan/sample-001400-X-Y.png\n",
            "Saved samples_cyclegan/sample-001400-Y-X.png\n",
            "Iteration [ 1600/ 5000] | d_real_loss: 0.0275 | d_Y_loss: 0.0096 | d_X_loss: 0.0251 | d_fake_loss: 0.0347 | g_loss: 6.7715\n",
            "Saved samples_cyclegan/sample-001600-X-Y.png\n",
            "Saved samples_cyclegan/sample-001600-Y-X.png\n",
            "Iteration [ 1800/ 5000] | d_real_loss: 0.0197 | d_Y_loss: 0.0093 | d_X_loss: 0.0461 | d_fake_loss: 0.0554 | g_loss: 6.4430\n",
            "Saved samples_cyclegan/sample-001800-X-Y.png\n",
            "Saved samples_cyclegan/sample-001800-Y-X.png\n",
            "Iteration [ 2000/ 5000] | d_real_loss: 0.0317 | d_Y_loss: 0.0087 | d_X_loss: 0.0169 | d_fake_loss: 0.0256 | g_loss: 6.7761\n",
            "Saved samples_cyclegan/sample-002000-X-Y.png\n",
            "Saved samples_cyclegan/sample-002000-Y-X.png\n",
            "Iteration [ 2200/ 5000] | d_real_loss: 0.0235 | d_Y_loss: 0.0093 | d_X_loss: 0.0291 | d_fake_loss: 0.0384 | g_loss: 6.1530\n",
            "Saved samples_cyclegan/sample-002200-X-Y.png\n",
            "Saved samples_cyclegan/sample-002200-Y-X.png\n",
            "Iteration [ 2400/ 5000] | d_real_loss: 0.0378 | d_Y_loss: 0.0136 | d_X_loss: 0.0172 | d_fake_loss: 0.0307 | g_loss: 6.0852\n",
            "Saved samples_cyclegan/sample-002400-X-Y.png\n",
            "Saved samples_cyclegan/sample-002400-Y-X.png\n",
            "Iteration [ 2600/ 5000] | d_real_loss: 0.0544 | d_Y_loss: 0.0142 | d_X_loss: 0.0147 | d_fake_loss: 0.0289 | g_loss: 5.6750\n",
            "Saved samples_cyclegan/sample-002600-X-Y.png\n",
            "Saved samples_cyclegan/sample-002600-Y-X.png\n",
            "Iteration [ 2800/ 5000] | d_real_loss: 0.0213 | d_Y_loss: 0.0106 | d_X_loss: 0.0257 | d_fake_loss: 0.0364 | g_loss: 6.5423\n",
            "Saved samples_cyclegan/sample-002800-X-Y.png\n",
            "Saved samples_cyclegan/sample-002800-Y-X.png\n",
            "Iteration [ 3000/ 5000] | d_real_loss: 0.0169 | d_Y_loss: 0.0046 | d_X_loss: 0.0260 | d_fake_loss: 0.0306 | g_loss: 6.0913\n",
            "Saved samples_cyclegan/sample-003000-X-Y.png\n",
            "Saved samples_cyclegan/sample-003000-Y-X.png\n",
            "Iteration [ 3200/ 5000] | d_real_loss: 0.0453 | d_Y_loss: 0.0119 | d_X_loss: 0.0208 | d_fake_loss: 0.0327 | g_loss: 6.3443\n",
            "Saved samples_cyclegan/sample-003200-X-Y.png\n",
            "Saved samples_cyclegan/sample-003200-Y-X.png\n",
            "Iteration [ 3400/ 5000] | d_real_loss: 0.0207 | d_Y_loss: 0.0060 | d_X_loss: 0.0209 | d_fake_loss: 0.0269 | g_loss: 6.8673\n",
            "Saved samples_cyclegan/sample-003400-X-Y.png\n",
            "Saved samples_cyclegan/sample-003400-Y-X.png\n",
            "Iteration [ 3600/ 5000] | d_real_loss: 0.0386 | d_Y_loss: 0.0089 | d_X_loss: 0.0179 | d_fake_loss: 0.0268 | g_loss: 7.0299\n",
            "Saved samples_cyclegan/sample-003600-X-Y.png\n",
            "Saved samples_cyclegan/sample-003600-Y-X.png\n",
            "Iteration [ 3800/ 5000] | d_real_loss: 0.0173 | d_Y_loss: 0.0093 | d_X_loss: 0.0205 | d_fake_loss: 0.0298 | g_loss: 6.0836\n",
            "Saved samples_cyclegan/sample-003800-X-Y.png\n",
            "Saved samples_cyclegan/sample-003800-Y-X.png\n",
            "Iteration [ 4000/ 5000] | d_real_loss: 0.0145 | d_Y_loss: 0.0074 | d_X_loss: 0.0144 | d_fake_loss: 0.0217 | g_loss: 5.4821\n",
            "Saved samples_cyclegan/sample-004000-X-Y.png\n",
            "Saved samples_cyclegan/sample-004000-Y-X.png\n",
            "Iteration [ 4200/ 5000] | d_real_loss: 0.0288 | d_Y_loss: 0.0166 | d_X_loss: 0.0097 | d_fake_loss: 0.0264 | g_loss: 5.6425\n",
            "Saved samples_cyclegan/sample-004200-X-Y.png\n",
            "Saved samples_cyclegan/sample-004200-Y-X.png\n",
            "Iteration [ 4400/ 5000] | d_real_loss: 0.0172 | d_Y_loss: 0.0098 | d_X_loss: 0.0139 | d_fake_loss: 0.0237 | g_loss: 6.0061\n",
            "Saved samples_cyclegan/sample-004400-X-Y.png\n",
            "Saved samples_cyclegan/sample-004400-Y-X.png\n",
            "Iteration [ 4600/ 5000] | d_real_loss: 0.0181 | d_Y_loss: 0.0080 | d_X_loss: 0.0123 | d_fake_loss: 0.0203 | g_loss: 5.8089\n",
            "Saved samples_cyclegan/sample-004600-X-Y.png\n",
            "Saved samples_cyclegan/sample-004600-Y-X.png\n",
            "Iteration [ 4800/ 5000] | d_real_loss: 0.0254 | d_Y_loss: 0.0132 | d_X_loss: 0.0243 | d_fake_loss: 0.0375 | g_loss: 5.8112\n",
            "Saved samples_cyclegan/sample-004800-X-Y.png\n",
            "Saved samples_cyclegan/sample-004800-Y-X.png\n",
            "Iteration [ 5000/ 5000] | d_real_loss: 0.0144 | d_Y_loss: 0.0071 | d_X_loss: 0.0261 | d_fake_loss: 0.0332 | g_loss: 6.0566\n",
            "Saved samples_cyclegan/sample-005000-X-Y.png\n",
            "Saved samples_cyclegan/sample-005000-Y-X.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HZAhfWBkAUQa",
        "colab_type": "code",
        "outputId": "5f64286b-49b8-4a62-8f85-539f6f1c4117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 2\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'image_size':32, \n",
        "              'g_conv_dim':32, \n",
        "              'd_conv_dim':32,\n",
        "              'init_zero_weights': False,\n",
        "              'num_workers': 0,\n",
        "              'train_iters':5000,\n",
        "              'X':'Apple',\n",
        "              'Y':'Windows',\n",
        "              'lambda_cycle': 0.015,\n",
        "              'lr':0.0003,\n",
        "              'beta1':0.3,\n",
        "              'beta2':0.999,\n",
        "              'batch_size':32, \n",
        "              'checkpoint_dir': 'checkpoints_cyclegan',\n",
        "              'sample_dir': 'samples_cyclegan',\n",
        "              'load': None,\n",
        "              'log_step':200,\n",
        "              'sample_every':200,\n",
        "              'checkpoint_every':1000,\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "\n",
        "print_opts(args)\n",
        "G_XtoY, G_YtoX, D_X, D_Y = train(args)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                           sample_every: 200                                    \n",
            "                           lambda_cycle: 0.015                                  \n",
            "                       checkpoint_every: 1000                                   \n",
            "                             batch_size: 32                                     \n",
            "                                      Y: Windows                                \n",
            "                             image_size: 32                                     \n",
            "                         checkpoint_dir: checkpoints_cyclegan                   \n",
            "                                      X: Apple                                  \n",
            "                             d_conv_dim: 32                                     \n",
            "                            train_iters: 5000                                   \n",
            "                             sample_dir: samples_cyclegan                       \n",
            "                               log_step: 200                                    \n",
            "                                     lr: 0.0003                                 \n",
            "                                  beta2: 0.999                                  \n",
            "                                  beta1: 0.3                                    \n",
            "                             g_conv_dim: 32                                     \n",
            "================================================================================\n",
            "                 G_XtoY                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                 G_YtoX                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_X                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_Y                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/torchvision/transforms/transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Models moved to GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  \"color for transparency\")\n",
            "/usr/local/lib/python2.7/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [  200/ 5000] | d_real_loss: 0.0720 | d_Y_loss: 0.0319 | d_X_loss: 0.0449 | d_fake_loss: 0.0767 | g_loss: 8.2151\n",
            "Saved samples_cyclegan/sample-000200-X-Y.png\n",
            "Saved samples_cyclegan/sample-000200-Y-X.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:210: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:215: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [  400/ 5000] | d_real_loss: 0.0391 | d_Y_loss: 0.0146 | d_X_loss: 0.0336 | d_fake_loss: 0.0482 | g_loss: 6.8604\n",
            "Saved samples_cyclegan/sample-000400-X-Y.png\n",
            "Saved samples_cyclegan/sample-000400-Y-X.png\n",
            "Iteration [  600/ 5000] | d_real_loss: 0.0466 | d_Y_loss: 0.0271 | d_X_loss: 0.0252 | d_fake_loss: 0.0522 | g_loss: 6.9290\n",
            "Saved samples_cyclegan/sample-000600-X-Y.png\n",
            "Saved samples_cyclegan/sample-000600-Y-X.png\n",
            "Iteration [  800/ 5000] | d_real_loss: 0.0336 | d_Y_loss: 0.0172 | d_X_loss: 0.0335 | d_fake_loss: 0.0507 | g_loss: 6.9717\n",
            "Saved samples_cyclegan/sample-000800-X-Y.png\n",
            "Saved samples_cyclegan/sample-000800-Y-X.png\n",
            "Iteration [ 1000/ 5000] | d_real_loss: 0.0348 | d_Y_loss: 0.0133 | d_X_loss: 0.0108 | d_fake_loss: 0.0241 | g_loss: 6.6303\n",
            "Saved samples_cyclegan/sample-001000-X-Y.png\n",
            "Saved samples_cyclegan/sample-001000-Y-X.png\n",
            "Iteration [ 1200/ 5000] | d_real_loss: 0.0171 | d_Y_loss: 0.0148 | d_X_loss: 0.0134 | d_fake_loss: 0.0282 | g_loss: 6.3934\n",
            "Saved samples_cyclegan/sample-001200-X-Y.png\n",
            "Saved samples_cyclegan/sample-001200-Y-X.png\n",
            "Iteration [ 1400/ 5000] | d_real_loss: 0.0230 | d_Y_loss: 0.0097 | d_X_loss: 0.0174 | d_fake_loss: 0.0272 | g_loss: 6.3219\n",
            "Saved samples_cyclegan/sample-001400-X-Y.png\n",
            "Saved samples_cyclegan/sample-001400-Y-X.png\n",
            "Iteration [ 1600/ 5000] | d_real_loss: 0.0188 | d_Y_loss: 0.0109 | d_X_loss: 0.0212 | d_fake_loss: 0.0321 | g_loss: 6.2329\n",
            "Saved samples_cyclegan/sample-001600-X-Y.png\n",
            "Saved samples_cyclegan/sample-001600-Y-X.png\n",
            "Iteration [ 1800/ 5000] | d_real_loss: 0.0359 | d_Y_loss: 0.0262 | d_X_loss: 0.0166 | d_fake_loss: 0.0427 | g_loss: 7.2141\n",
            "Saved samples_cyclegan/sample-001800-X-Y.png\n",
            "Saved samples_cyclegan/sample-001800-Y-X.png\n",
            "Iteration [ 2000/ 5000] | d_real_loss: 0.0344 | d_Y_loss: 0.0084 | d_X_loss: 0.0150 | d_fake_loss: 0.0234 | g_loss: 5.7508\n",
            "Saved samples_cyclegan/sample-002000-X-Y.png\n",
            "Saved samples_cyclegan/sample-002000-Y-X.png\n",
            "Iteration [ 2200/ 5000] | d_real_loss: 0.0409 | d_Y_loss: 0.0164 | d_X_loss: 0.0175 | d_fake_loss: 0.0339 | g_loss: 6.3635\n",
            "Saved samples_cyclegan/sample-002200-X-Y.png\n",
            "Saved samples_cyclegan/sample-002200-Y-X.png\n",
            "Iteration [ 2400/ 5000] | d_real_loss: 0.0300 | d_Y_loss: 0.0058 | d_X_loss: 0.0190 | d_fake_loss: 0.0248 | g_loss: 5.9456\n",
            "Saved samples_cyclegan/sample-002400-X-Y.png\n",
            "Saved samples_cyclegan/sample-002400-Y-X.png\n",
            "Iteration [ 2600/ 5000] | d_real_loss: 0.0287 | d_Y_loss: 0.0048 | d_X_loss: 0.0133 | d_fake_loss: 0.0181 | g_loss: 6.5993\n",
            "Saved samples_cyclegan/sample-002600-X-Y.png\n",
            "Saved samples_cyclegan/sample-002600-Y-X.png\n",
            "Iteration [ 2800/ 5000] | d_real_loss: 0.0537 | d_Y_loss: 0.0206 | d_X_loss: 0.0284 | d_fake_loss: 0.0491 | g_loss: 6.3708\n",
            "Saved samples_cyclegan/sample-002800-X-Y.png\n",
            "Saved samples_cyclegan/sample-002800-Y-X.png\n",
            "Iteration [ 3000/ 5000] | d_real_loss: 0.0790 | d_Y_loss: 0.0122 | d_X_loss: 0.0437 | d_fake_loss: 0.0559 | g_loss: 6.7697\n",
            "Saved samples_cyclegan/sample-003000-X-Y.png\n",
            "Saved samples_cyclegan/sample-003000-Y-X.png\n",
            "Iteration [ 3200/ 5000] | d_real_loss: 0.0659 | d_Y_loss: 0.0095 | d_X_loss: 0.0470 | d_fake_loss: 0.0564 | g_loss: 6.5022\n",
            "Saved samples_cyclegan/sample-003200-X-Y.png\n",
            "Saved samples_cyclegan/sample-003200-Y-X.png\n",
            "Iteration [ 3400/ 5000] | d_real_loss: 0.0401 | d_Y_loss: 0.0100 | d_X_loss: 0.0153 | d_fake_loss: 0.0253 | g_loss: 6.0584\n",
            "Saved samples_cyclegan/sample-003400-X-Y.png\n",
            "Saved samples_cyclegan/sample-003400-Y-X.png\n",
            "Iteration [ 3600/ 5000] | d_real_loss: 0.0233 | d_Y_loss: 0.0132 | d_X_loss: 0.0084 | d_fake_loss: 0.0215 | g_loss: 6.7345\n",
            "Saved samples_cyclegan/sample-003600-X-Y.png\n",
            "Saved samples_cyclegan/sample-003600-Y-X.png\n",
            "Iteration [ 3800/ 5000] | d_real_loss: 0.0240 | d_Y_loss: 0.0084 | d_X_loss: 0.0174 | d_fake_loss: 0.0259 | g_loss: 5.8568\n",
            "Saved samples_cyclegan/sample-003800-X-Y.png\n",
            "Saved samples_cyclegan/sample-003800-Y-X.png\n",
            "Iteration [ 4000/ 5000] | d_real_loss: 0.0279 | d_Y_loss: 0.0118 | d_X_loss: 0.0493 | d_fake_loss: 0.0611 | g_loss: 6.1948\n",
            "Saved samples_cyclegan/sample-004000-X-Y.png\n",
            "Saved samples_cyclegan/sample-004000-Y-X.png\n",
            "Iteration [ 4200/ 5000] | d_real_loss: 0.0376 | d_Y_loss: 0.0060 | d_X_loss: 0.0457 | d_fake_loss: 0.0517 | g_loss: 6.6128\n",
            "Saved samples_cyclegan/sample-004200-X-Y.png\n",
            "Saved samples_cyclegan/sample-004200-Y-X.png\n",
            "Iteration [ 4400/ 5000] | d_real_loss: 0.0495 | d_Y_loss: 0.0053 | d_X_loss: 0.0582 | d_fake_loss: 0.0634 | g_loss: 5.9590\n",
            "Saved samples_cyclegan/sample-004400-X-Y.png\n",
            "Saved samples_cyclegan/sample-004400-Y-X.png\n",
            "Iteration [ 4600/ 5000] | d_real_loss: 0.0137 | d_Y_loss: 0.0184 | d_X_loss: 0.0063 | d_fake_loss: 0.0247 | g_loss: 6.9618\n",
            "Saved samples_cyclegan/sample-004600-X-Y.png\n",
            "Saved samples_cyclegan/sample-004600-Y-X.png\n",
            "Iteration [ 4800/ 5000] | d_real_loss: 0.0291 | d_Y_loss: 0.0114 | d_X_loss: 0.0062 | d_fake_loss: 0.0177 | g_loss: 6.6064\n",
            "Saved samples_cyclegan/sample-004800-X-Y.png\n",
            "Saved samples_cyclegan/sample-004800-Y-X.png\n",
            "Iteration [ 5000/ 5000] | d_real_loss: 0.0394 | d_Y_loss: 0.0089 | d_X_loss: 0.0448 | d_fake_loss: 0.0536 | g_loss: 7.3569\n",
            "Saved samples_cyclegan/sample-005000-X-Y.png\n",
            "Saved samples_cyclegan/sample-005000-Y-X.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PqHKAdbvF2fM",
        "colab_type": "code",
        "outputId": "e44e7b91-6820-4c17-efef-fede8ca5cca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3366
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 2\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'image_size':32, \n",
        "              'g_conv_dim':32, \n",
        "              'd_conv_dim':32,\n",
        "              'init_zero_weights': False,\n",
        "              'num_workers': 0,\n",
        "              'train_iters':5000,\n",
        "              'X':'Apple',\n",
        "              'Y':'Windows',\n",
        "              'lambda_cycle': 0,\n",
        "              'lr':0.0003,\n",
        "              'beta1':0.3,\n",
        "              'beta2':0.999,\n",
        "              'batch_size':32, \n",
        "              'checkpoint_dir': 'checkpoints_cyclegan',\n",
        "              'sample_dir': 'samples_cyclegan',\n",
        "              'load': None,\n",
        "              'log_step':200,\n",
        "              'sample_every':200,\n",
        "              'checkpoint_every':1000,\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "\n",
        "print_opts(args)\n",
        "G_XtoY, G_YtoX, D_X, D_Y = train(args)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                           sample_every: 200                                    \n",
            "                       checkpoint_every: 1000                                   \n",
            "                             batch_size: 32                                     \n",
            "                                      Y: Windows                                \n",
            "                             image_size: 32                                     \n",
            "                         checkpoint_dir: checkpoints_cyclegan                   \n",
            "                                      X: Apple                                  \n",
            "                             d_conv_dim: 32                                     \n",
            "                            train_iters: 5000                                   \n",
            "                             sample_dir: samples_cyclegan                       \n",
            "                               log_step: 200                                    \n",
            "                                     lr: 0.0003                                 \n",
            "                                  beta2: 0.999                                  \n",
            "                                  beta1: 0.3                                    \n",
            "                             g_conv_dim: 32                                     \n",
            "================================================================================\n",
            "                 G_XtoY                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                 G_YtoX                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_X                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_Y                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "Models moved to GPU.\n",
            "Iteration [  200/ 5000] | d_real_loss: 0.2547 | d_Y_loss: 0.0880 | d_X_loss: 0.1535 | d_fake_loss: 0.2415 | g_loss: 0.6318\n",
            "Saved samples_cyclegan/sample-000200-X-Y.png\n",
            "Saved samples_cyclegan/sample-000200-Y-X.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:210: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:215: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [  400/ 5000] | d_real_loss: 0.2052 | d_Y_loss: 0.0781 | d_X_loss: 0.1323 | d_fake_loss: 0.2105 | g_loss: 0.7168\n",
            "Saved samples_cyclegan/sample-000400-X-Y.png\n",
            "Saved samples_cyclegan/sample-000400-Y-X.png\n",
            "Iteration [  600/ 5000] | d_real_loss: 0.1480 | d_Y_loss: 0.0353 | d_X_loss: 0.1225 | d_fake_loss: 0.1578 | g_loss: 1.1773\n",
            "Saved samples_cyclegan/sample-000600-X-Y.png\n",
            "Saved samples_cyclegan/sample-000600-Y-X.png\n",
            "Iteration [  800/ 5000] | d_real_loss: 0.1523 | d_Y_loss: 0.0308 | d_X_loss: 0.1205 | d_fake_loss: 0.1513 | g_loss: 1.1050\n",
            "Saved samples_cyclegan/sample-000800-X-Y.png\n",
            "Saved samples_cyclegan/sample-000800-Y-X.png\n",
            "Iteration [ 1000/ 5000] | d_real_loss: 0.1301 | d_Y_loss: 0.0489 | d_X_loss: 0.0921 | d_fake_loss: 0.1410 | g_loss: 1.1289\n",
            "Saved samples_cyclegan/sample-001000-X-Y.png\n",
            "Saved samples_cyclegan/sample-001000-Y-X.png\n",
            "Iteration [ 1200/ 5000] | d_real_loss: 0.0913 | d_Y_loss: 0.0229 | d_X_loss: 0.0619 | d_fake_loss: 0.0847 | g_loss: 1.2250\n",
            "Saved samples_cyclegan/sample-001200-X-Y.png\n",
            "Saved samples_cyclegan/sample-001200-Y-X.png\n",
            "Iteration [ 1400/ 5000] | d_real_loss: 0.0907 | d_Y_loss: 0.0455 | d_X_loss: 0.0687 | d_fake_loss: 0.1142 | g_loss: 1.2262\n",
            "Saved samples_cyclegan/sample-001400-X-Y.png\n",
            "Saved samples_cyclegan/sample-001400-Y-X.png\n",
            "Iteration [ 1600/ 5000] | d_real_loss: 0.0813 | d_Y_loss: 0.0357 | d_X_loss: 0.0793 | d_fake_loss: 0.1150 | g_loss: 1.2630\n",
            "Saved samples_cyclegan/sample-001600-X-Y.png\n",
            "Saved samples_cyclegan/sample-001600-Y-X.png\n",
            "Iteration [ 1800/ 5000] | d_real_loss: 0.0729 | d_Y_loss: 0.0221 | d_X_loss: 0.0567 | d_fake_loss: 0.0788 | g_loss: 1.0173\n",
            "Saved samples_cyclegan/sample-001800-X-Y.png\n",
            "Saved samples_cyclegan/sample-001800-Y-X.png\n",
            "Iteration [ 2000/ 5000] | d_real_loss: 0.0493 | d_Y_loss: 0.0108 | d_X_loss: 0.0588 | d_fake_loss: 0.0696 | g_loss: 1.0246\n",
            "Saved samples_cyclegan/sample-002000-X-Y.png\n",
            "Saved samples_cyclegan/sample-002000-Y-X.png\n",
            "Iteration [ 2200/ 5000] | d_real_loss: 0.0937 | d_Y_loss: 0.0285 | d_X_loss: 0.0629 | d_fake_loss: 0.0914 | g_loss: 1.1942\n",
            "Saved samples_cyclegan/sample-002200-X-Y.png\n",
            "Saved samples_cyclegan/sample-002200-Y-X.png\n",
            "Iteration [ 2400/ 5000] | d_real_loss: 0.1530 | d_Y_loss: 0.0406 | d_X_loss: 0.0475 | d_fake_loss: 0.0881 | g_loss: 1.2053\n",
            "Saved samples_cyclegan/sample-002400-X-Y.png\n",
            "Saved samples_cyclegan/sample-002400-Y-X.png\n",
            "Iteration [ 2600/ 5000] | d_real_loss: 0.0576 | d_Y_loss: 0.0198 | d_X_loss: 0.0429 | d_fake_loss: 0.0627 | g_loss: 1.1565\n",
            "Saved samples_cyclegan/sample-002600-X-Y.png\n",
            "Saved samples_cyclegan/sample-002600-Y-X.png\n",
            "Iteration [ 2800/ 5000] | d_real_loss: 0.1844 | d_Y_loss: 0.0794 | d_X_loss: 0.0415 | d_fake_loss: 0.1209 | g_loss: 1.1826\n",
            "Saved samples_cyclegan/sample-002800-X-Y.png\n",
            "Saved samples_cyclegan/sample-002800-Y-X.png\n",
            "Iteration [ 3000/ 5000] | d_real_loss: 0.1177 | d_Y_loss: 0.0097 | d_X_loss: 0.0452 | d_fake_loss: 0.0549 | g_loss: 0.9476\n",
            "Saved samples_cyclegan/sample-003000-X-Y.png\n",
            "Saved samples_cyclegan/sample-003000-Y-X.png\n",
            "Iteration [ 3200/ 5000] | d_real_loss: 0.1389 | d_Y_loss: 0.0126 | d_X_loss: 0.0328 | d_fake_loss: 0.0454 | g_loss: 1.0003\n",
            "Saved samples_cyclegan/sample-003200-X-Y.png\n",
            "Saved samples_cyclegan/sample-003200-Y-X.png\n",
            "Iteration [ 3400/ 5000] | d_real_loss: 0.0728 | d_Y_loss: 0.0151 | d_X_loss: 0.0342 | d_fake_loss: 0.0493 | g_loss: 0.9423\n",
            "Saved samples_cyclegan/sample-003400-X-Y.png\n",
            "Saved samples_cyclegan/sample-003400-Y-X.png\n",
            "Iteration [ 3600/ 5000] | d_real_loss: 0.0735 | d_Y_loss: 0.0280 | d_X_loss: 0.0440 | d_fake_loss: 0.0720 | g_loss: 1.1575\n",
            "Saved samples_cyclegan/sample-003600-X-Y.png\n",
            "Saved samples_cyclegan/sample-003600-Y-X.png\n",
            "Iteration [ 3800/ 5000] | d_real_loss: 0.0342 | d_Y_loss: 0.0120 | d_X_loss: 0.0582 | d_fake_loss: 0.0702 | g_loss: 1.0519\n",
            "Saved samples_cyclegan/sample-003800-X-Y.png\n",
            "Saved samples_cyclegan/sample-003800-Y-X.png\n",
            "Iteration [ 4000/ 5000] | d_real_loss: 0.0624 | d_Y_loss: 0.0367 | d_X_loss: 0.0747 | d_fake_loss: 0.1114 | g_loss: 0.8616\n",
            "Saved samples_cyclegan/sample-004000-X-Y.png\n",
            "Saved samples_cyclegan/sample-004000-Y-X.png\n",
            "Iteration [ 4200/ 5000] | d_real_loss: 0.0649 | d_Y_loss: 0.0227 | d_X_loss: 0.0770 | d_fake_loss: 0.0997 | g_loss: 1.0296\n",
            "Saved samples_cyclegan/sample-004200-X-Y.png\n",
            "Saved samples_cyclegan/sample-004200-Y-X.png\n",
            "Iteration [ 4400/ 5000] | d_real_loss: 0.0537 | d_Y_loss: 0.0121 | d_X_loss: 0.0945 | d_fake_loss: 0.1066 | g_loss: 1.0599\n",
            "Saved samples_cyclegan/sample-004400-X-Y.png\n",
            "Saved samples_cyclegan/sample-004400-Y-X.png\n",
            "Iteration [ 4600/ 5000] | d_real_loss: 0.0842 | d_Y_loss: 0.0131 | d_X_loss: 0.0655 | d_fake_loss: 0.0787 | g_loss: 1.0714\n",
            "Saved samples_cyclegan/sample-004600-X-Y.png\n",
            "Saved samples_cyclegan/sample-004600-Y-X.png\n",
            "Iteration [ 4800/ 5000] | d_real_loss: 0.0710 | d_Y_loss: 0.0625 | d_X_loss: 0.0292 | d_fake_loss: 0.0917 | g_loss: 1.1984\n",
            "Saved samples_cyclegan/sample-004800-X-Y.png\n",
            "Saved samples_cyclegan/sample-004800-Y-X.png\n",
            "Iteration [ 5000/ 5000] | d_real_loss: 0.0667 | d_Y_loss: 0.0200 | d_X_loss: 0.0542 | d_fake_loss: 0.0742 | g_loss: 1.0170\n",
            "Saved samples_cyclegan/sample-005000-X-Y.png\n",
            "Saved samples_cyclegan/sample-005000-Y-X.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-UH7HcmpHAEp",
        "colab_type": "code",
        "outputId": "5304bda0-1d53-495c-aefb-5a8463d3b1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3383
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 2\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'image_size':32, \n",
        "              'g_conv_dim':32, \n",
        "              'd_conv_dim':32,\n",
        "              'init_zero_weights': False,\n",
        "              'num_workers': 0,\n",
        "              'train_iters':5000,\n",
        "              'X':'Apple',\n",
        "              'Y':'Windows',\n",
        "              'lambda_cycle': 0.05,\n",
        "              'lr':0.0003,\n",
        "              'beta1':0.3,\n",
        "              'beta2':0.999,\n",
        "              'batch_size':32, \n",
        "              'checkpoint_dir': 'checkpoints_cyclegan',\n",
        "              'sample_dir': 'samples_cyclegan',\n",
        "              'load': None,\n",
        "              'log_step':200,\n",
        "              'sample_every':200,\n",
        "              'checkpoint_every':1000,\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "\n",
        "print_opts(args)\n",
        "G_XtoY, G_YtoX, D_X, D_Y = train(args)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                           sample_every: 200                                    \n",
            "                           lambda_cycle: 0.05                                   \n",
            "                       checkpoint_every: 1000                                   \n",
            "                             batch_size: 32                                     \n",
            "                                      Y: Windows                                \n",
            "                             image_size: 32                                     \n",
            "                         checkpoint_dir: checkpoints_cyclegan                   \n",
            "                                      X: Apple                                  \n",
            "                             d_conv_dim: 32                                     \n",
            "                            train_iters: 5000                                   \n",
            "                             sample_dir: samples_cyclegan                       \n",
            "                               log_step: 200                                    \n",
            "                                     lr: 0.0003                                 \n",
            "                                  beta2: 0.999                                  \n",
            "                                  beta1: 0.3                                    \n",
            "                             g_conv_dim: 32                                     \n",
            "================================================================================\n",
            "                 G_XtoY                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                 G_YtoX                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_X                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_Y                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "Models moved to GPU.\n",
            "Iteration [  200/ 5000] | d_real_loss: 0.0347 | d_Y_loss: 0.0137 | d_X_loss: 0.0081 | d_fake_loss: 0.0219 | g_loss: 22.9943\n",
            "Saved samples_cyclegan/sample-000200-X-Y.png\n",
            "Saved samples_cyclegan/sample-000200-Y-X.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:210: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:215: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [  400/ 5000] | d_real_loss: 0.0263 | d_Y_loss: 0.0115 | d_X_loss: 0.0124 | d_fake_loss: 0.0240 | g_loss: 17.9393\n",
            "Saved samples_cyclegan/sample-000400-X-Y.png\n",
            "Saved samples_cyclegan/sample-000400-Y-X.png\n",
            "Iteration [  600/ 5000] | d_real_loss: 0.0515 | d_Y_loss: 0.0157 | d_X_loss: 0.0284 | d_fake_loss: 0.0441 | g_loss: 17.4122\n",
            "Saved samples_cyclegan/sample-000600-X-Y.png\n",
            "Saved samples_cyclegan/sample-000600-Y-X.png\n",
            "Iteration [  800/ 5000] | d_real_loss: 0.0085 | d_Y_loss: 0.0042 | d_X_loss: 0.0030 | d_fake_loss: 0.0071 | g_loss: 16.7964\n",
            "Saved samples_cyclegan/sample-000800-X-Y.png\n",
            "Saved samples_cyclegan/sample-000800-Y-X.png\n",
            "Iteration [ 1000/ 5000] | d_real_loss: 0.0050 | d_Y_loss: 0.0067 | d_X_loss: 0.0063 | d_fake_loss: 0.0131 | g_loss: 16.3171\n",
            "Saved samples_cyclegan/sample-001000-X-Y.png\n",
            "Saved samples_cyclegan/sample-001000-Y-X.png\n",
            "Iteration [ 1200/ 5000] | d_real_loss: 0.0064 | d_Y_loss: 0.0036 | d_X_loss: 0.0086 | d_fake_loss: 0.0122 | g_loss: 16.5105\n",
            "Saved samples_cyclegan/sample-001200-X-Y.png\n",
            "Saved samples_cyclegan/sample-001200-Y-X.png\n",
            "Iteration [ 1400/ 5000] | d_real_loss: 0.0103 | d_Y_loss: 0.0079 | d_X_loss: 0.0032 | d_fake_loss: 0.0111 | g_loss: 15.7317\n",
            "Saved samples_cyclegan/sample-001400-X-Y.png\n",
            "Saved samples_cyclegan/sample-001400-Y-X.png\n",
            "Iteration [ 1600/ 5000] | d_real_loss: 0.0186 | d_Y_loss: 0.0067 | d_X_loss: 0.0023 | d_fake_loss: 0.0090 | g_loss: 15.2377\n",
            "Saved samples_cyclegan/sample-001600-X-Y.png\n",
            "Saved samples_cyclegan/sample-001600-Y-X.png\n",
            "Iteration [ 1800/ 5000] | d_real_loss: 0.0066 | d_Y_loss: 0.0017 | d_X_loss: 0.0038 | d_fake_loss: 0.0055 | g_loss: 15.2112\n",
            "Saved samples_cyclegan/sample-001800-X-Y.png\n",
            "Saved samples_cyclegan/sample-001800-Y-X.png\n",
            "Iteration [ 2000/ 5000] | d_real_loss: 0.0055 | d_Y_loss: 0.0079 | d_X_loss: 0.0052 | d_fake_loss: 0.0131 | g_loss: 12.8166\n",
            "Saved samples_cyclegan/sample-002000-X-Y.png\n",
            "Saved samples_cyclegan/sample-002000-Y-X.png\n",
            "Iteration [ 2200/ 5000] | d_real_loss: 0.0086 | d_Y_loss: 0.0038 | d_X_loss: 0.0139 | d_fake_loss: 0.0177 | g_loss: 14.5385\n",
            "Saved samples_cyclegan/sample-002200-X-Y.png\n",
            "Saved samples_cyclegan/sample-002200-Y-X.png\n",
            "Iteration [ 2400/ 5000] | d_real_loss: 0.0087 | d_Y_loss: 0.0021 | d_X_loss: 0.0058 | d_fake_loss: 0.0079 | g_loss: 12.9833\n",
            "Saved samples_cyclegan/sample-002400-X-Y.png\n",
            "Saved samples_cyclegan/sample-002400-Y-X.png\n",
            "Iteration [ 2600/ 5000] | d_real_loss: 0.0109 | d_Y_loss: 0.0022 | d_X_loss: 0.0029 | d_fake_loss: 0.0051 | g_loss: 16.0283\n",
            "Saved samples_cyclegan/sample-002600-X-Y.png\n",
            "Saved samples_cyclegan/sample-002600-Y-X.png\n",
            "Iteration [ 2800/ 5000] | d_real_loss: 0.0072 | d_Y_loss: 0.0028 | d_X_loss: 0.0051 | d_fake_loss: 0.0079 | g_loss: 14.6133\n",
            "Saved samples_cyclegan/sample-002800-X-Y.png\n",
            "Saved samples_cyclegan/sample-002800-Y-X.png\n",
            "Iteration [ 3000/ 5000] | d_real_loss: 0.0205 | d_Y_loss: 0.0093 | d_X_loss: 0.0280 | d_fake_loss: 0.0372 | g_loss: 14.7349\n",
            "Saved samples_cyclegan/sample-003000-X-Y.png\n",
            "Saved samples_cyclegan/sample-003000-Y-X.png\n",
            "Iteration [ 3200/ 5000] | d_real_loss: 0.0163 | d_Y_loss: 0.0058 | d_X_loss: 0.0216 | d_fake_loss: 0.0274 | g_loss: 13.8905\n",
            "Saved samples_cyclegan/sample-003200-X-Y.png\n",
            "Saved samples_cyclegan/sample-003200-Y-X.png\n",
            "Iteration [ 3400/ 5000] | d_real_loss: 0.0035 | d_Y_loss: 0.0027 | d_X_loss: 0.0175 | d_fake_loss: 0.0202 | g_loss: 13.1901\n",
            "Saved samples_cyclegan/sample-003400-X-Y.png\n",
            "Saved samples_cyclegan/sample-003400-Y-X.png\n",
            "Iteration [ 3600/ 5000] | d_real_loss: 0.0090 | d_Y_loss: 0.0022 | d_X_loss: 0.0017 | d_fake_loss: 0.0039 | g_loss: 15.5109\n",
            "Saved samples_cyclegan/sample-003600-X-Y.png\n",
            "Saved samples_cyclegan/sample-003600-Y-X.png\n",
            "Iteration [ 3800/ 5000] | d_real_loss: 0.0057 | d_Y_loss: 0.0027 | d_X_loss: 0.0024 | d_fake_loss: 0.0051 | g_loss: 13.1513\n",
            "Saved samples_cyclegan/sample-003800-X-Y.png\n",
            "Saved samples_cyclegan/sample-003800-Y-X.png\n",
            "Iteration [ 4000/ 5000] | d_real_loss: 0.0074 | d_Y_loss: 0.0014 | d_X_loss: 0.0013 | d_fake_loss: 0.0028 | g_loss: 12.8724\n",
            "Saved samples_cyclegan/sample-004000-X-Y.png\n",
            "Saved samples_cyclegan/sample-004000-Y-X.png\n",
            "Iteration [ 4200/ 5000] | d_real_loss: 0.0031 | d_Y_loss: 0.0027 | d_X_loss: 0.0018 | d_fake_loss: 0.0044 | g_loss: 13.7148\n",
            "Saved samples_cyclegan/sample-004200-X-Y.png\n",
            "Saved samples_cyclegan/sample-004200-Y-X.png\n",
            "Iteration [ 4400/ 5000] | d_real_loss: 0.0050 | d_Y_loss: 0.0027 | d_X_loss: 0.0030 | d_fake_loss: 0.0056 | g_loss: 13.4562\n",
            "Saved samples_cyclegan/sample-004400-X-Y.png\n",
            "Saved samples_cyclegan/sample-004400-Y-X.png\n",
            "Iteration [ 4600/ 5000] | d_real_loss: 0.0027 | d_Y_loss: 0.0067 | d_X_loss: 0.0011 | d_fake_loss: 0.0077 | g_loss: 18.0034\n",
            "Saved samples_cyclegan/sample-004600-X-Y.png\n",
            "Saved samples_cyclegan/sample-004600-Y-X.png\n",
            "Iteration [ 4800/ 5000] | d_real_loss: 0.0085 | d_Y_loss: 0.0016 | d_X_loss: 0.0017 | d_fake_loss: 0.0032 | g_loss: 14.4648\n",
            "Saved samples_cyclegan/sample-004800-X-Y.png\n",
            "Saved samples_cyclegan/sample-004800-Y-X.png\n",
            "Iteration [ 5000/ 5000] | d_real_loss: 0.0034 | d_Y_loss: 0.0018 | d_X_loss: 0.0051 | d_fake_loss: 0.0069 | g_loss: 16.0963\n",
            "Saved samples_cyclegan/sample-005000-X-Y.png\n",
            "Saved samples_cyclegan/sample-005000-Y-X.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sk_dcO6BHD6S",
        "colab_type": "code",
        "outputId": "2b349360-1e15-4cf5-cc67-50c93bfeb948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3383
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 2\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'image_size':32, \n",
        "              'g_conv_dim':32, \n",
        "              'd_conv_dim':32,\n",
        "              'init_zero_weights': False,\n",
        "              'num_workers': 0,\n",
        "              'train_iters':5000,\n",
        "              'X':'Apple',\n",
        "              'Y':'Windows',\n",
        "              'lambda_cycle': 0.1,\n",
        "              'lr':0.0003,\n",
        "              'beta1':0.3,\n",
        "              'beta2':0.999,\n",
        "              'batch_size':32, \n",
        "              'checkpoint_dir': 'checkpoints_cyclegan',\n",
        "              'sample_dir': 'samples_cyclegan',\n",
        "              'load': None,\n",
        "              'log_step':200,\n",
        "              'sample_every':200,\n",
        "              'checkpoint_every':1000,\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "\n",
        "print_opts(args)\n",
        "G_XtoY, G_YtoX, D_X, D_Y = train(args)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                           sample_every: 200                                    \n",
            "                           lambda_cycle: 0.1                                    \n",
            "                       checkpoint_every: 1000                                   \n",
            "                             batch_size: 32                                     \n",
            "                                      Y: Windows                                \n",
            "                             image_size: 32                                     \n",
            "                         checkpoint_dir: checkpoints_cyclegan                   \n",
            "                                      X: Apple                                  \n",
            "                             d_conv_dim: 32                                     \n",
            "                            train_iters: 5000                                   \n",
            "                             sample_dir: samples_cyclegan                       \n",
            "                               log_step: 200                                    \n",
            "                                     lr: 0.0003                                 \n",
            "                                  beta2: 0.999                                  \n",
            "                                  beta1: 0.3                                    \n",
            "                             g_conv_dim: 32                                     \n",
            "================================================================================\n",
            "                 G_XtoY                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                 G_YtoX                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_X                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_Y                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "Models moved to GPU.\n",
            "Iteration [  200/ 5000] | d_real_loss: 0.0170 | d_Y_loss: 0.0051 | d_X_loss: 0.0061 | d_fake_loss: 0.0112 | g_loss: 44.6585\n",
            "Saved samples_cyclegan/sample-000200-X-Y.png\n",
            "Saved samples_cyclegan/sample-000200-Y-X.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:210: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:215: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [  400/ 5000] | d_real_loss: 0.0138 | d_Y_loss: 0.0136 | d_X_loss: 0.0071 | d_fake_loss: 0.0206 | g_loss: 34.6337\n",
            "Saved samples_cyclegan/sample-000400-X-Y.png\n",
            "Saved samples_cyclegan/sample-000400-Y-X.png\n",
            "Iteration [  600/ 5000] | d_real_loss: 0.0260 | d_Y_loss: 0.0045 | d_X_loss: 0.0078 | d_fake_loss: 0.0123 | g_loss: 31.6228\n",
            "Saved samples_cyclegan/sample-000600-X-Y.png\n",
            "Saved samples_cyclegan/sample-000600-Y-X.png\n",
            "Iteration [  800/ 5000] | d_real_loss: 0.0038 | d_Y_loss: 0.0025 | d_X_loss: 0.0128 | d_fake_loss: 0.0152 | g_loss: 31.6523\n",
            "Saved samples_cyclegan/sample-000800-X-Y.png\n",
            "Saved samples_cyclegan/sample-000800-Y-X.png\n",
            "Iteration [ 1000/ 5000] | d_real_loss: 0.0033 | d_Y_loss: 0.0026 | d_X_loss: 0.0015 | d_fake_loss: 0.0041 | g_loss: 31.2718\n",
            "Saved samples_cyclegan/sample-001000-X-Y.png\n",
            "Saved samples_cyclegan/sample-001000-Y-X.png\n",
            "Iteration [ 1200/ 5000] | d_real_loss: 0.0070 | d_Y_loss: 0.0044 | d_X_loss: 0.0100 | d_fake_loss: 0.0144 | g_loss: 29.9027\n",
            "Saved samples_cyclegan/sample-001200-X-Y.png\n",
            "Saved samples_cyclegan/sample-001200-Y-X.png\n",
            "Iteration [ 1400/ 5000] | d_real_loss: 0.0049 | d_Y_loss: 0.0147 | d_X_loss: 0.0034 | d_fake_loss: 0.0181 | g_loss: 30.4407\n",
            "Saved samples_cyclegan/sample-001400-X-Y.png\n",
            "Saved samples_cyclegan/sample-001400-Y-X.png\n",
            "Iteration [ 1600/ 5000] | d_real_loss: 0.0152 | d_Y_loss: 0.0095 | d_X_loss: 0.0073 | d_fake_loss: 0.0168 | g_loss: 28.6001\n",
            "Saved samples_cyclegan/sample-001600-X-Y.png\n",
            "Saved samples_cyclegan/sample-001600-Y-X.png\n",
            "Iteration [ 1800/ 5000] | d_real_loss: 0.0036 | d_Y_loss: 0.0023 | d_X_loss: 0.0019 | d_fake_loss: 0.0042 | g_loss: 27.9478\n",
            "Saved samples_cyclegan/sample-001800-X-Y.png\n",
            "Saved samples_cyclegan/sample-001800-Y-X.png\n",
            "Iteration [ 2000/ 5000] | d_real_loss: 0.0049 | d_Y_loss: 0.0088 | d_X_loss: 0.0099 | d_fake_loss: 0.0187 | g_loss: 24.5954\n",
            "Saved samples_cyclegan/sample-002000-X-Y.png\n",
            "Saved samples_cyclegan/sample-002000-Y-X.png\n",
            "Iteration [ 2200/ 5000] | d_real_loss: 0.0057 | d_Y_loss: 0.0029 | d_X_loss: 0.0057 | d_fake_loss: 0.0086 | g_loss: 26.9355\n",
            "Saved samples_cyclegan/sample-002200-X-Y.png\n",
            "Saved samples_cyclegan/sample-002200-Y-X.png\n",
            "Iteration [ 2400/ 5000] | d_real_loss: 0.0034 | d_Y_loss: 0.0007 | d_X_loss: 0.0024 | d_fake_loss: 0.0031 | g_loss: 23.7060\n",
            "Saved samples_cyclegan/sample-002400-X-Y.png\n",
            "Saved samples_cyclegan/sample-002400-Y-X.png\n",
            "Iteration [ 2600/ 5000] | d_real_loss: 0.0048 | d_Y_loss: 0.0015 | d_X_loss: 0.0013 | d_fake_loss: 0.0028 | g_loss: 28.2182\n",
            "Saved samples_cyclegan/sample-002600-X-Y.png\n",
            "Saved samples_cyclegan/sample-002600-Y-X.png\n",
            "Iteration [ 2800/ 5000] | d_real_loss: 0.0016 | d_Y_loss: 0.0012 | d_X_loss: 0.0024 | d_fake_loss: 0.0036 | g_loss: 27.6969\n",
            "Saved samples_cyclegan/sample-002800-X-Y.png\n",
            "Saved samples_cyclegan/sample-002800-Y-X.png\n",
            "Iteration [ 3000/ 5000] | d_real_loss: 0.0027 | d_Y_loss: 0.0080 | d_X_loss: 0.0033 | d_fake_loss: 0.0113 | g_loss: 28.8270\n",
            "Saved samples_cyclegan/sample-003000-X-Y.png\n",
            "Saved samples_cyclegan/sample-003000-Y-X.png\n",
            "Iteration [ 3200/ 5000] | d_real_loss: 0.0076 | d_Y_loss: 0.0044 | d_X_loss: 0.0058 | d_fake_loss: 0.0102 | g_loss: 25.5608\n",
            "Saved samples_cyclegan/sample-003200-X-Y.png\n",
            "Saved samples_cyclegan/sample-003200-Y-X.png\n",
            "Iteration [ 3400/ 5000] | d_real_loss: 0.0026 | d_Y_loss: 0.0016 | d_X_loss: 0.0043 | d_fake_loss: 0.0058 | g_loss: 23.6038\n",
            "Saved samples_cyclegan/sample-003400-X-Y.png\n",
            "Saved samples_cyclegan/sample-003400-Y-X.png\n",
            "Iteration [ 3600/ 5000] | d_real_loss: 0.0037 | d_Y_loss: 0.0012 | d_X_loss: 0.0014 | d_fake_loss: 0.0026 | g_loss: 28.6024\n",
            "Saved samples_cyclegan/sample-003600-X-Y.png\n",
            "Saved samples_cyclegan/sample-003600-Y-X.png\n",
            "Iteration [ 3800/ 5000] | d_real_loss: 0.0098 | d_Y_loss: 0.0004 | d_X_loss: 0.0005 | d_fake_loss: 0.0009 | g_loss: 24.0778\n",
            "Saved samples_cyclegan/sample-003800-X-Y.png\n",
            "Saved samples_cyclegan/sample-003800-Y-X.png\n",
            "Iteration [ 4000/ 5000] | d_real_loss: 0.0072 | d_Y_loss: 0.0004 | d_X_loss: 0.0018 | d_fake_loss: 0.0022 | g_loss: 22.8796\n",
            "Saved samples_cyclegan/sample-004000-X-Y.png\n",
            "Saved samples_cyclegan/sample-004000-Y-X.png\n",
            "Iteration [ 4200/ 5000] | d_real_loss: 0.0012 | d_Y_loss: 0.0016 | d_X_loss: 0.0002 | d_fake_loss: 0.0018 | g_loss: 25.7198\n",
            "Saved samples_cyclegan/sample-004200-X-Y.png\n",
            "Saved samples_cyclegan/sample-004200-Y-X.png\n",
            "Iteration [ 4400/ 5000] | d_real_loss: 0.0039 | d_Y_loss: 0.0011 | d_X_loss: 0.0005 | d_fake_loss: 0.0016 | g_loss: 24.6424\n",
            "Saved samples_cyclegan/sample-004400-X-Y.png\n",
            "Saved samples_cyclegan/sample-004400-Y-X.png\n",
            "Iteration [ 4600/ 5000] | d_real_loss: 0.0047 | d_Y_loss: 0.0009 | d_X_loss: 0.0022 | d_fake_loss: 0.0031 | g_loss: 32.7416\n",
            "Saved samples_cyclegan/sample-004600-X-Y.png\n",
            "Saved samples_cyclegan/sample-004600-Y-X.png\n",
            "Iteration [ 4800/ 5000] | d_real_loss: 0.0020 | d_Y_loss: 0.0006 | d_X_loss: 0.0013 | d_fake_loss: 0.0019 | g_loss: 24.3503\n",
            "Saved samples_cyclegan/sample-004800-X-Y.png\n",
            "Saved samples_cyclegan/sample-004800-Y-X.png\n",
            "Iteration [ 5000/ 5000] | d_real_loss: 0.0012 | d_Y_loss: 0.0015 | d_X_loss: 0.0011 | d_fake_loss: 0.0026 | g_loss: 29.6810\n",
            "Saved samples_cyclegan/sample-005000-X-Y.png\n",
            "Saved samples_cyclegan/sample-005000-Y-X.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "StfoksmOHGzO",
        "colab_type": "code",
        "outputId": "bc2cd5cf-6603-4c40-bd22-28022bf59484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3383
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 2\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'image_size':32, \n",
        "              'g_conv_dim':32, \n",
        "              'd_conv_dim':32,\n",
        "              'init_zero_weights': False,\n",
        "              'num_workers': 0,\n",
        "              'train_iters':5000,\n",
        "              'X':'Apple',\n",
        "              'Y':'Windows',\n",
        "              'lambda_cycle': 0.5,\n",
        "              'lr':0.0003,\n",
        "              'beta1':0.3,\n",
        "              'beta2':0.999,\n",
        "              'batch_size':32, \n",
        "              'checkpoint_dir': 'checkpoints_cyclegan',\n",
        "              'sample_dir': 'samples_cyclegan',\n",
        "              'load': None,\n",
        "              'log_step':200,\n",
        "              'sample_every':200,\n",
        "              'checkpoint_every':1000,\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "\n",
        "print_opts(args)\n",
        "G_XtoY, G_YtoX, D_X, D_Y = train(args)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                           sample_every: 200                                    \n",
            "                           lambda_cycle: 0.5                                    \n",
            "                       checkpoint_every: 1000                                   \n",
            "                             batch_size: 32                                     \n",
            "                                      Y: Windows                                \n",
            "                             image_size: 32                                     \n",
            "                         checkpoint_dir: checkpoints_cyclegan                   \n",
            "                                      X: Apple                                  \n",
            "                             d_conv_dim: 32                                     \n",
            "                            train_iters: 5000                                   \n",
            "                             sample_dir: samples_cyclegan                       \n",
            "                               log_step: 200                                    \n",
            "                                     lr: 0.0003                                 \n",
            "                                  beta2: 0.999                                  \n",
            "                                  beta1: 0.3                                    \n",
            "                             g_conv_dim: 32                                     \n",
            "================================================================================\n",
            "                 G_XtoY                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                 G_YtoX                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_X                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_Y                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "Models moved to GPU.\n",
            "Iteration [  200/ 5000] | d_real_loss: 0.0053 | d_Y_loss: 0.0044 | d_X_loss: 0.0026 | d_fake_loss: 0.0070 | g_loss: 220.0770\n",
            "Saved samples_cyclegan/sample-000200-X-Y.png\n",
            "Saved samples_cyclegan/sample-000200-Y-X.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:210: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:215: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [  400/ 5000] | d_real_loss: 0.0020 | d_Y_loss: 0.0038 | d_X_loss: 0.0016 | d_fake_loss: 0.0054 | g_loss: 164.7740\n",
            "Saved samples_cyclegan/sample-000400-X-Y.png\n",
            "Saved samples_cyclegan/sample-000400-Y-X.png\n",
            "Iteration [  600/ 5000] | d_real_loss: 0.0041 | d_Y_loss: 0.0022 | d_X_loss: 0.0012 | d_fake_loss: 0.0034 | g_loss: 154.2386\n",
            "Saved samples_cyclegan/sample-000600-X-Y.png\n",
            "Saved samples_cyclegan/sample-000600-Y-X.png\n",
            "Iteration [  800/ 5000] | d_real_loss: 0.0014 | d_Y_loss: 0.0010 | d_X_loss: 0.0042 | d_fake_loss: 0.0052 | g_loss: 146.0490\n",
            "Saved samples_cyclegan/sample-000800-X-Y.png\n",
            "Saved samples_cyclegan/sample-000800-Y-X.png\n",
            "Iteration [ 1000/ 5000] | d_real_loss: 0.0014 | d_Y_loss: 0.0013 | d_X_loss: 0.0003 | d_fake_loss: 0.0017 | g_loss: 147.4310\n",
            "Saved samples_cyclegan/sample-001000-X-Y.png\n",
            "Saved samples_cyclegan/sample-001000-Y-X.png\n",
            "Iteration [ 1200/ 5000] | d_real_loss: 0.0023 | d_Y_loss: 0.0016 | d_X_loss: 0.0028 | d_fake_loss: 0.0044 | g_loss: 142.1798\n",
            "Saved samples_cyclegan/sample-001200-X-Y.png\n",
            "Saved samples_cyclegan/sample-001200-Y-X.png\n",
            "Iteration [ 1400/ 5000] | d_real_loss: 0.0042 | d_Y_loss: 0.0017 | d_X_loss: 0.0005 | d_fake_loss: 0.0023 | g_loss: 143.8407\n",
            "Saved samples_cyclegan/sample-001400-X-Y.png\n",
            "Saved samples_cyclegan/sample-001400-Y-X.png\n",
            "Iteration [ 1600/ 5000] | d_real_loss: 0.0045 | d_Y_loss: 0.0008 | d_X_loss: 0.0011 | d_fake_loss: 0.0018 | g_loss: 134.1027\n",
            "Saved samples_cyclegan/sample-001600-X-Y.png\n",
            "Saved samples_cyclegan/sample-001600-Y-X.png\n",
            "Iteration [ 1800/ 5000] | d_real_loss: 0.0008 | d_Y_loss: 0.0007 | d_X_loss: 0.0008 | d_fake_loss: 0.0015 | g_loss: 141.7601\n",
            "Saved samples_cyclegan/sample-001800-X-Y.png\n",
            "Saved samples_cyclegan/sample-001800-Y-X.png\n",
            "Iteration [ 2000/ 5000] | d_real_loss: 0.0012 | d_Y_loss: 0.0003 | d_X_loss: 0.0004 | d_fake_loss: 0.0007 | g_loss: 114.8823\n",
            "Saved samples_cyclegan/sample-002000-X-Y.png\n",
            "Saved samples_cyclegan/sample-002000-Y-X.png\n",
            "Iteration [ 2200/ 5000] | d_real_loss: 0.0013 | d_Y_loss: 0.0003 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 125.4514\n",
            "Saved samples_cyclegan/sample-002200-X-Y.png\n",
            "Saved samples_cyclegan/sample-002200-Y-X.png\n",
            "Iteration [ 2400/ 5000] | d_real_loss: 0.0029 | d_Y_loss: 0.0005 | d_X_loss: 0.0006 | d_fake_loss: 0.0011 | g_loss: 115.5274\n",
            "Saved samples_cyclegan/sample-002400-X-Y.png\n",
            "Saved samples_cyclegan/sample-002400-Y-X.png\n",
            "Iteration [ 2600/ 5000] | d_real_loss: 0.0010 | d_Y_loss: 0.0002 | d_X_loss: 0.0003 | d_fake_loss: 0.0005 | g_loss: 137.4647\n",
            "Saved samples_cyclegan/sample-002600-X-Y.png\n",
            "Saved samples_cyclegan/sample-002600-Y-X.png\n",
            "Iteration [ 2800/ 5000] | d_real_loss: 0.0018 | d_Y_loss: 0.0003 | d_X_loss: 0.0019 | d_fake_loss: 0.0022 | g_loss: 132.3263\n",
            "Saved samples_cyclegan/sample-002800-X-Y.png\n",
            "Saved samples_cyclegan/sample-002800-Y-X.png\n",
            "Iteration [ 3000/ 5000] | d_real_loss: 0.0008 | d_Y_loss: 0.0013 | d_X_loss: 0.0002 | d_fake_loss: 0.0015 | g_loss: 142.1972\n",
            "Saved samples_cyclegan/sample-003000-X-Y.png\n",
            "Saved samples_cyclegan/sample-003000-Y-X.png\n",
            "Iteration [ 3200/ 5000] | d_real_loss: 0.0011 | d_Y_loss: 0.0001 | d_X_loss: 0.0009 | d_fake_loss: 0.0010 | g_loss: 117.6407\n",
            "Saved samples_cyclegan/sample-003200-X-Y.png\n",
            "Saved samples_cyclegan/sample-003200-Y-X.png\n",
            "Iteration [ 3400/ 5000] | d_real_loss: 0.0019 | d_Y_loss: 0.0016 | d_X_loss: 0.0003 | d_fake_loss: 0.0019 | g_loss: 114.7591\n",
            "Saved samples_cyclegan/sample-003400-X-Y.png\n",
            "Saved samples_cyclegan/sample-003400-Y-X.png\n",
            "Iteration [ 3600/ 5000] | d_real_loss: 0.0012 | d_Y_loss: 0.0007 | d_X_loss: 0.0004 | d_fake_loss: 0.0011 | g_loss: 134.8347\n",
            "Saved samples_cyclegan/sample-003600-X-Y.png\n",
            "Saved samples_cyclegan/sample-003600-Y-X.png\n",
            "Iteration [ 3800/ 5000] | d_real_loss: 0.0023 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0002 | g_loss: 115.2321\n",
            "Saved samples_cyclegan/sample-003800-X-Y.png\n",
            "Saved samples_cyclegan/sample-003800-Y-X.png\n",
            "Iteration [ 4000/ 5000] | d_real_loss: 0.0003 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0003 | g_loss: 110.7674\n",
            "Saved samples_cyclegan/sample-004000-X-Y.png\n",
            "Saved samples_cyclegan/sample-004000-Y-X.png\n",
            "Iteration [ 4200/ 5000] | d_real_loss: 0.0005 | d_Y_loss: 0.0002 | d_X_loss: 0.0001 | d_fake_loss: 0.0003 | g_loss: 124.6050\n",
            "Saved samples_cyclegan/sample-004200-X-Y.png\n",
            "Saved samples_cyclegan/sample-004200-Y-X.png\n",
            "Iteration [ 4400/ 5000] | d_real_loss: 0.0007 | d_Y_loss: 0.0022 | d_X_loss: 0.0001 | d_fake_loss: 0.0023 | g_loss: 116.7533\n",
            "Saved samples_cyclegan/sample-004400-X-Y.png\n",
            "Saved samples_cyclegan/sample-004400-Y-X.png\n",
            "Iteration [ 4600/ 5000] | d_real_loss: 0.0014 | d_Y_loss: 0.0001 | d_X_loss: 0.0001 | d_fake_loss: 0.0001 | g_loss: 164.9952\n",
            "Saved samples_cyclegan/sample-004600-X-Y.png\n",
            "Saved samples_cyclegan/sample-004600-Y-X.png\n",
            "Iteration [ 4800/ 5000] | d_real_loss: 0.0006 | d_Y_loss: 0.0001 | d_X_loss: 0.0002 | d_fake_loss: 0.0004 | g_loss: 121.7826\n",
            "Saved samples_cyclegan/sample-004800-X-Y.png\n",
            "Saved samples_cyclegan/sample-004800-Y-X.png\n",
            "Iteration [ 5000/ 5000] | d_real_loss: 0.0002 | d_Y_loss: 0.0002 | d_X_loss: 0.0004 | d_fake_loss: 0.0006 | g_loss: 145.0316\n",
            "Saved samples_cyclegan/sample-005000-X-Y.png\n",
            "Saved samples_cyclegan/sample-005000-Y-X.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kZ07wixwHJlx",
        "colab_type": "code",
        "outputId": "a211a4d7-4e60-40c1-eda1-e5a9e790fd98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3383
        }
      },
      "cell_type": "code",
      "source": [
        "SEED = 2\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'image_size':32, \n",
        "              'g_conv_dim':32, \n",
        "              'd_conv_dim':32,\n",
        "              'init_zero_weights': False,\n",
        "              'num_workers': 0,\n",
        "              'train_iters':5000,\n",
        "              'X':'Apple',\n",
        "              'Y':'Windows',\n",
        "              'lambda_cycle': 0.010,\n",
        "              'lr':0.0003,\n",
        "              'beta1':0.3,\n",
        "              'beta2':0.999,\n",
        "              'batch_size':32, \n",
        "              'checkpoint_dir': 'checkpoints_cyclegan',\n",
        "              'sample_dir': 'samples_cyclegan',\n",
        "              'load': None,\n",
        "              'log_step':200,\n",
        "              'sample_every':200,\n",
        "              'checkpoint_every':1000,\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "\n",
        "print_opts(args)\n",
        "G_XtoY, G_YtoX, D_X, D_Y = train(args)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                           sample_every: 200                                    \n",
            "                           lambda_cycle: 0.01                                   \n",
            "                       checkpoint_every: 1000                                   \n",
            "                             batch_size: 32                                     \n",
            "                                      Y: Windows                                \n",
            "                             image_size: 32                                     \n",
            "                         checkpoint_dir: checkpoints_cyclegan                   \n",
            "                                      X: Apple                                  \n",
            "                             d_conv_dim: 32                                     \n",
            "                            train_iters: 5000                                   \n",
            "                             sample_dir: samples_cyclegan                       \n",
            "                               log_step: 200                                    \n",
            "                                     lr: 0.0003                                 \n",
            "                                  beta2: 0.999                                  \n",
            "                                  beta1: 0.3                                    \n",
            "                             g_conv_dim: 32                                     \n",
            "================================================================================\n",
            "                 G_XtoY                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                 G_YtoX                \n",
            "---------------------------------------\n",
            "CycleGenerator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (resnet_block): ResnetBlock(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (upconv2): Sequential(\n",
            "    (0): Upsample(scale_factor=2, mode=nearest)\n",
            "    (1): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_X                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_Y                  \n",
            "---------------------------------------\n",
            "DCDiscriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "Models moved to GPU.\n",
            "Iteration [  200/ 5000] | d_real_loss: 0.0912 | d_Y_loss: 0.0381 | d_X_loss: 0.0602 | d_fake_loss: 0.0983 | g_loss: 5.9810\n",
            "Saved samples_cyclegan/sample-000200-X-Y.png\n",
            "Saved samples_cyclegan/sample-000200-Y-X.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:210: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:215: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration [  400/ 5000] | d_real_loss: 0.0749 | d_Y_loss: 0.0299 | d_X_loss: 0.0439 | d_fake_loss: 0.0737 | g_loss: 5.2179\n",
            "Saved samples_cyclegan/sample-000400-X-Y.png\n",
            "Saved samples_cyclegan/sample-000400-Y-X.png\n",
            "Iteration [  600/ 5000] | d_real_loss: 0.0324 | d_Y_loss: 0.0470 | d_X_loss: 0.0258 | d_fake_loss: 0.0728 | g_loss: 5.3329\n",
            "Saved samples_cyclegan/sample-000600-X-Y.png\n",
            "Saved samples_cyclegan/sample-000600-Y-X.png\n",
            "Iteration [  800/ 5000] | d_real_loss: 0.0361 | d_Y_loss: 0.0175 | d_X_loss: 0.0451 | d_fake_loss: 0.0626 | g_loss: 5.4145\n",
            "Saved samples_cyclegan/sample-000800-X-Y.png\n",
            "Saved samples_cyclegan/sample-000800-Y-X.png\n",
            "Iteration [ 1000/ 5000] | d_real_loss: 0.0395 | d_Y_loss: 0.0137 | d_X_loss: 0.0270 | d_fake_loss: 0.0407 | g_loss: 5.0518\n",
            "Saved samples_cyclegan/sample-001000-X-Y.png\n",
            "Saved samples_cyclegan/sample-001000-Y-X.png\n",
            "Iteration [ 1200/ 5000] | d_real_loss: 0.0449 | d_Y_loss: 0.0124 | d_X_loss: 0.0204 | d_fake_loss: 0.0328 | g_loss: 4.9687\n",
            "Saved samples_cyclegan/sample-001200-X-Y.png\n",
            "Saved samples_cyclegan/sample-001200-Y-X.png\n",
            "Iteration [ 1400/ 5000] | d_real_loss: 0.0317 | d_Y_loss: 0.0120 | d_X_loss: 0.0155 | d_fake_loss: 0.0276 | g_loss: 5.1726\n",
            "Saved samples_cyclegan/sample-001400-X-Y.png\n",
            "Saved samples_cyclegan/sample-001400-Y-X.png\n",
            "Iteration [ 1600/ 5000] | d_real_loss: 0.0286 | d_Y_loss: 0.0126 | d_X_loss: 0.0525 | d_fake_loss: 0.0652 | g_loss: 4.8258\n",
            "Saved samples_cyclegan/sample-001600-X-Y.png\n",
            "Saved samples_cyclegan/sample-001600-Y-X.png\n",
            "Iteration [ 1800/ 5000] | d_real_loss: 0.0236 | d_Y_loss: 0.0384 | d_X_loss: 0.0155 | d_fake_loss: 0.0539 | g_loss: 5.7398\n",
            "Saved samples_cyclegan/sample-001800-X-Y.png\n",
            "Saved samples_cyclegan/sample-001800-Y-X.png\n",
            "Iteration [ 2000/ 5000] | d_real_loss: 0.0233 | d_Y_loss: 0.0142 | d_X_loss: 0.0235 | d_fake_loss: 0.0377 | g_loss: 4.4471\n",
            "Saved samples_cyclegan/sample-002000-X-Y.png\n",
            "Saved samples_cyclegan/sample-002000-Y-X.png\n",
            "Iteration [ 2200/ 5000] | d_real_loss: 0.0555 | d_Y_loss: 0.0192 | d_X_loss: 0.0385 | d_fake_loss: 0.0577 | g_loss: 4.9590\n",
            "Saved samples_cyclegan/sample-002200-X-Y.png\n",
            "Saved samples_cyclegan/sample-002200-Y-X.png\n",
            "Iteration [ 2400/ 5000] | d_real_loss: 0.1068 | d_Y_loss: 0.0089 | d_X_loss: 0.0389 | d_fake_loss: 0.0478 | g_loss: 4.6395\n",
            "Saved samples_cyclegan/sample-002400-X-Y.png\n",
            "Saved samples_cyclegan/sample-002400-Y-X.png\n",
            "Iteration [ 2600/ 5000] | d_real_loss: 0.0437 | d_Y_loss: 0.0101 | d_X_loss: 0.0299 | d_fake_loss: 0.0400 | g_loss: 4.9600\n",
            "Saved samples_cyclegan/sample-002600-X-Y.png\n",
            "Saved samples_cyclegan/sample-002600-Y-X.png\n",
            "Iteration [ 2800/ 5000] | d_real_loss: 0.0812 | d_Y_loss: 0.0318 | d_X_loss: 0.0299 | d_fake_loss: 0.0616 | g_loss: 5.2091\n",
            "Saved samples_cyclegan/sample-002800-X-Y.png\n",
            "Saved samples_cyclegan/sample-002800-Y-X.png\n",
            "Iteration [ 3000/ 5000] | d_real_loss: 0.1084 | d_Y_loss: 0.0171 | d_X_loss: 0.0376 | d_fake_loss: 0.0548 | g_loss: 5.1749\n",
            "Saved samples_cyclegan/sample-003000-X-Y.png\n",
            "Saved samples_cyclegan/sample-003000-Y-X.png\n",
            "Iteration [ 3200/ 5000] | d_real_loss: 0.0903 | d_Y_loss: 0.0082 | d_X_loss: 0.0348 | d_fake_loss: 0.0430 | g_loss: 4.8953\n",
            "Saved samples_cyclegan/sample-003200-X-Y.png\n",
            "Saved samples_cyclegan/sample-003200-Y-X.png\n",
            "Iteration [ 3400/ 5000] | d_real_loss: 0.0764 | d_Y_loss: 0.0092 | d_X_loss: 0.0328 | d_fake_loss: 0.0420 | g_loss: 4.6638\n",
            "Saved samples_cyclegan/sample-003400-X-Y.png\n",
            "Saved samples_cyclegan/sample-003400-Y-X.png\n",
            "Iteration [ 3600/ 5000] | d_real_loss: 0.0205 | d_Y_loss: 0.0065 | d_X_loss: 0.0165 | d_fake_loss: 0.0231 | g_loss: 5.3006\n",
            "Saved samples_cyclegan/sample-003600-X-Y.png\n",
            "Saved samples_cyclegan/sample-003600-Y-X.png\n",
            "Iteration [ 3800/ 5000] | d_real_loss: 0.0517 | d_Y_loss: 0.0060 | d_X_loss: 0.0386 | d_fake_loss: 0.0446 | g_loss: 4.6367\n",
            "Saved samples_cyclegan/sample-003800-X-Y.png\n",
            "Saved samples_cyclegan/sample-003800-Y-X.png\n",
            "Iteration [ 4000/ 5000] | d_real_loss: 0.0369 | d_Y_loss: 0.0081 | d_X_loss: 0.0904 | d_fake_loss: 0.0986 | g_loss: 5.0157\n",
            "Saved samples_cyclegan/sample-004000-X-Y.png\n",
            "Saved samples_cyclegan/sample-004000-Y-X.png\n",
            "Iteration [ 4200/ 5000] | d_real_loss: 0.0264 | d_Y_loss: 0.0107 | d_X_loss: 0.0502 | d_fake_loss: 0.0609 | g_loss: 5.1832\n",
            "Saved samples_cyclegan/sample-004200-X-Y.png\n",
            "Saved samples_cyclegan/sample-004200-Y-X.png\n",
            "Iteration [ 4400/ 5000] | d_real_loss: 0.0418 | d_Y_loss: 0.0133 | d_X_loss: 0.0554 | d_fake_loss: 0.0686 | g_loss: 4.7917\n",
            "Saved samples_cyclegan/sample-004400-X-Y.png\n",
            "Saved samples_cyclegan/sample-004400-Y-X.png\n",
            "Iteration [ 4600/ 5000] | d_real_loss: 0.0207 | d_Y_loss: 0.0119 | d_X_loss: 0.0077 | d_fake_loss: 0.0196 | g_loss: 5.5527\n",
            "Saved samples_cyclegan/sample-004600-X-Y.png\n",
            "Saved samples_cyclegan/sample-004600-Y-X.png\n",
            "Iteration [ 4800/ 5000] | d_real_loss: 0.0308 | d_Y_loss: 0.0346 | d_X_loss: 0.0238 | d_fake_loss: 0.0583 | g_loss: 5.3077\n",
            "Saved samples_cyclegan/sample-004800-X-Y.png\n",
            "Saved samples_cyclegan/sample-004800-Y-X.png\n",
            "Iteration [ 5000/ 5000] | d_real_loss: 0.0601 | d_Y_loss: 0.0142 | d_X_loss: 0.0195 | d_fake_loss: 0.0337 | g_loss: 5.5350\n",
            "Saved samples_cyclegan/sample-005000-X-Y.png\n",
            "Saved samples_cyclegan/sample-005000-Y-X.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3hq6F2i5btTJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}